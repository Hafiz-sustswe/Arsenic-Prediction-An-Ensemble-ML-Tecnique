{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22f4533",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'selectFromModel' from 'sklearn.feature_selection' (C:\\MiniConda\\Lib\\site-packages\\sklearn\\feature_selection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m selectFromModel\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'selectFromModel' from 'sklearn.feature_selection' (C:\\MiniConda\\Lib\\site-packages\\sklearn\\feature_selection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import selectFromModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20e9bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=\"Ruby.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2bbbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the csv file into a dataframe\n",
    "data=pd.read_csv(\"Ruby.csv\",encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a245b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample no</th>\n",
       "      <th>As</th>\n",
       "      <th>pH</th>\n",
       "      <th>EC</th>\n",
       "      <th>TDS</th>\n",
       "      <th>Cl</th>\n",
       "      <th>SO4</th>\n",
       "      <th>NO3</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Mn</th>\n",
       "      <th>Na</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Mg</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>PO4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6.90</td>\n",
       "      <td>2000</td>\n",
       "      <td>770</td>\n",
       "      <td>12.34</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>68.23</td>\n",
       "      <td>3.13</td>\n",
       "      <td>195.59</td>\n",
       "      <td>151.69</td>\n",
       "      <td>400.32</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>7.46</td>\n",
       "      <td>885</td>\n",
       "      <td>250</td>\n",
       "      <td>11.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.79</td>\n",
       "      <td>40.14</td>\n",
       "      <td>2.00</td>\n",
       "      <td>83.37</td>\n",
       "      <td>51.54</td>\n",
       "      <td>450.36</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>7.95</td>\n",
       "      <td>890</td>\n",
       "      <td>210</td>\n",
       "      <td>14.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.74</td>\n",
       "      <td>32.79</td>\n",
       "      <td>2.87</td>\n",
       "      <td>41.68</td>\n",
       "      <td>51.54</td>\n",
       "      <td>350.28</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7.02</td>\n",
       "      <td>828</td>\n",
       "      <td>250</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>22.38</td>\n",
       "      <td>1.91</td>\n",
       "      <td>80.16</td>\n",
       "      <td>35.98</td>\n",
       "      <td>500.40</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>7.35</td>\n",
       "      <td>905</td>\n",
       "      <td>240</td>\n",
       "      <td>12.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>33.22</td>\n",
       "      <td>2.15</td>\n",
       "      <td>101.00</td>\n",
       "      <td>33.06</td>\n",
       "      <td>350.28</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample no  As    pH    EC   TDS     Cl   SO4   NO3    Fe    Mn     Na  \\\n",
       "0          1  25  6.90  2000   770  12.34  1.13  0.10  0.38  0.38  68.23   \n",
       "1          2  20  7.46   885   250  11.09  0.12  0.07  0.29  0.79  40.14   \n",
       "2          3  50  7.95   890   210  14.11  0.07  0.04  0.44  0.74  32.79   \n",
       "3          4  10  7.02   828   250  13.94  0.11  0.06  0.52  0.52  22.38   \n",
       "4          5  23  7.35   905   240  12.74  0.76  0.61  0.01  0.01  33.22   \n",
       "\n",
       "      K      Ca      Mg    HCO3   PO4  \n",
       "0  3.13  195.59  151.69  400.32  1.22  \n",
       "1  2.00   83.37   51.54  450.36  0.71  \n",
       "2  2.87   41.68   51.54  350.28  1.08  \n",
       "3  1.91   80.16   35.98  500.40  0.92  \n",
       "4  2.15  101.00   33.06  350.28  0.52  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e80e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 16 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Sample no  30 non-null     int64  \n",
      " 1   As         30 non-null     int64  \n",
      " 2   pH         30 non-null     float64\n",
      " 3   EC         30 non-null     int64  \n",
      " 4    TDS       30 non-null     int64  \n",
      " 5    Cl        30 non-null     float64\n",
      " 6   SO4        30 non-null     float64\n",
      " 7   NO3        30 non-null     float64\n",
      " 8   Fe         30 non-null     float64\n",
      " 9   Mn         30 non-null     float64\n",
      " 10  Na         30 non-null     float64\n",
      " 11  K          30 non-null     float64\n",
      " 12  Ca         30 non-null     float64\n",
      " 13  Mg         30 non-null     float64\n",
      " 14  HCO3       30 non-null     float64\n",
      " 15  PO4        30 non-null     float64\n",
      "dtypes: float64(12), int64(4)\n",
      "memory usage: 3.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3d482f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1:Define a threshold amnd convert to Binary Labels\n",
    "threshold = 10 # adjust threshold based on data\n",
    "binary_labels = np.where(data[\"As\"]> threshold,1,0)\n",
    "data[\"As_binary\"] = binary_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca556bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 15) (9, 15) (21,) (9,)\n"
     ]
    }
   ],
   "source": [
    "#step 2: Split the Data\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(data.drop([\"As\",\"As_binary\"],axis=1),binary_labels,test_size=.30,random_state=0)\n",
    "print(xtrain.shape,xtest.shape,ytrain.shape,ytest.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9dd10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3:standard scaling\n",
    "scaler=StandardScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.transform(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "061bff9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Step 4:Feature selection using L1 Regularization (Logistic Regression\n",
    "model=LogisticRegression()\n",
    "model=model.fit(xtrain,ytrain)\n",
    "pred=model.predict(xtest)\n",
    "lr_probability =model.predict_proba(xtest)[:,1]\n",
    "print(\"Accuracy : \", accuracy_score(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c864c8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 1.0\n",
      "Recall: 0.8888888888888888\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'specificity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision :\u001b[39m\u001b[38;5;124m\"\u001b[39m,precision_score(ytest,pred))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall:\u001b[39m\u001b[38;5;124m\"\u001b[39m,recall_score(ytest,pred))\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(specificity(ytest,pred))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'specificity' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Precision :\",precision_score(ytest,pred))\n",
    "print(\"Recall:\",recall_score(ytest,pred))\n",
    "print(specificity(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb0052b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix : [[0 0]\n",
      " [1 8]]\n"
     ]
    }
   ],
   "source": [
    "print(\"confusion_matrix :\",confusion_matrix(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c11c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "026ba4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "xn=scaler.fit_transform(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80d685f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4012060064.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[43], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    model1 = class.predict(xn)\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model1 = class.predict(xn)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48b9e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest = RandomForestClassifier()\n",
    "randomforest=randomforest.fit(xtrain, ytrain)\n",
    "y_pred = randomforest.predict(xtest)\n",
    "RF_probability = randomforest.predict_proba(xtest)[:,1]\n",
    "\n",
    "print(accuracy_score(y_pred,ytest))\n",
    "#print(\"ROC_AUC Score:\",AUC_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba78add4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb=XGBClassifier(eta=0.05)\n",
    "XGB_fit=xgb.fit(xtrain, ytrain)\n",
    "y_predict = XGB_fit.predict(xtest)\n",
    "XGB_probability = XGB_fit.predict_proba(xtest)[:,1]\n",
    "\n",
    "acc_xgb=accuracy_score(ytest,y_predict)\n",
    "\n",
    "print(accuracy_score(y_predict,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6067fc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(xtrain, ytrain)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(xtest)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(ytest, y_pred)\n",
    "\n",
    "print(accuracy_score(y_pred,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ea7738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555555555555556\n",
      "1.0\n",
      "0.8888888888888888\n",
      "[[0 0]\n",
      " [1 8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(xtrain, ytrain)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(xtest)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "print(accuracy_score(y_pred,ytest))\n",
    "print(precision_score(ytest,pred))\n",
    "print(recall_score(ytest,pred))\n",
    "\n",
    "print(confusion_matrix(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cca1717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 1.0\n",
      "Recall: 0.8888888888888888\n",
      "confusion_matrix : [[0 0]\n",
      " [1 8]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision :\",precision_score(ytest,pred))\n",
    "print(\"Recall:\",recall_score(ytest,pred))\n",
    "\n",
    "print(\"confusion_matrix :\",confusion_matrix(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8210f801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n",
      "Precision : 1.0\n",
      "Recall: 0.8888888888888888\n",
      "confusion_matrix : [[0 0]\n",
      " [1 8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(xtrain, ytrain)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(xtest)\n",
    "print(accuracy_score(y_pred,ytest))\n",
    "print(\"Precision :\",precision_score(ytest,pred))\n",
    "print(\"Recall:\",recall_score(ytest,pred))\n",
    "\n",
    "print(\"confusion_matrix :\",confusion_matrix(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "477a1990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 1.0\n",
      "Recall: 0.8888888888888888\n",
      "confusion_matrix : [[0 0]\n",
      " [1 8]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision :\",precision_score(ytest,pred))\n",
    "print(\"Recall:\",recall_score(ytest,pred))\n",
    "\n",
    "print(\"confusion_matrix :\",confusion_matrix(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db7d4710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample no</th>\n",
       "      <th>As</th>\n",
       "      <th>pH</th>\n",
       "      <th>EC</th>\n",
       "      <th>TDS</th>\n",
       "      <th>Cl</th>\n",
       "      <th>SO4</th>\n",
       "      <th>NO3</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Mn</th>\n",
       "      <th>Na</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Mg</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>PO4</th>\n",
       "      <th>As_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6.90</td>\n",
       "      <td>2000</td>\n",
       "      <td>770</td>\n",
       "      <td>12.34</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>68.23</td>\n",
       "      <td>3.13</td>\n",
       "      <td>195.59</td>\n",
       "      <td>151.69</td>\n",
       "      <td>400.32</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>7.46</td>\n",
       "      <td>885</td>\n",
       "      <td>250</td>\n",
       "      <td>11.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.79</td>\n",
       "      <td>40.14</td>\n",
       "      <td>2.00</td>\n",
       "      <td>83.37</td>\n",
       "      <td>51.54</td>\n",
       "      <td>450.36</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>7.95</td>\n",
       "      <td>890</td>\n",
       "      <td>210</td>\n",
       "      <td>14.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.74</td>\n",
       "      <td>32.79</td>\n",
       "      <td>2.87</td>\n",
       "      <td>41.68</td>\n",
       "      <td>51.54</td>\n",
       "      <td>350.28</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7.02</td>\n",
       "      <td>828</td>\n",
       "      <td>250</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>22.38</td>\n",
       "      <td>1.91</td>\n",
       "      <td>80.16</td>\n",
       "      <td>35.98</td>\n",
       "      <td>500.40</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>7.35</td>\n",
       "      <td>905</td>\n",
       "      <td>240</td>\n",
       "      <td>12.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>33.22</td>\n",
       "      <td>2.15</td>\n",
       "      <td>101.00</td>\n",
       "      <td>33.06</td>\n",
       "      <td>350.28</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>7.05</td>\n",
       "      <td>1043</td>\n",
       "      <td>320</td>\n",
       "      <td>13.29</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.80</td>\n",
       "      <td>40.00</td>\n",
       "      <td>2.21</td>\n",
       "      <td>128.26</td>\n",
       "      <td>24.31</td>\n",
       "      <td>500.40</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>7.44</td>\n",
       "      <td>642</td>\n",
       "      <td>200</td>\n",
       "      <td>14.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>31.53</td>\n",
       "      <td>1.66</td>\n",
       "      <td>107.41</td>\n",
       "      <td>23.34</td>\n",
       "      <td>350.28</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>7.49</td>\n",
       "      <td>366</td>\n",
       "      <td>120</td>\n",
       "      <td>14.93</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1.82</td>\n",
       "      <td>67.33</td>\n",
       "      <td>11.67</td>\n",
       "      <td>250.20</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>6.98</td>\n",
       "      <td>1270</td>\n",
       "      <td>380</td>\n",
       "      <td>14.73</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>35.56</td>\n",
       "      <td>1.25</td>\n",
       "      <td>166.73</td>\n",
       "      <td>37.92</td>\n",
       "      <td>550.44</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1015</td>\n",
       "      <td>250</td>\n",
       "      <td>13.98</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.81</td>\n",
       "      <td>37.10</td>\n",
       "      <td>1.28</td>\n",
       "      <td>81.76</td>\n",
       "      <td>34.03</td>\n",
       "      <td>450.36</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>7.18</td>\n",
       "      <td>632</td>\n",
       "      <td>190</td>\n",
       "      <td>13.79</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.91</td>\n",
       "      <td>40.43</td>\n",
       "      <td>1.54</td>\n",
       "      <td>99.39</td>\n",
       "      <td>34.03</td>\n",
       "      <td>400.32</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>6.95</td>\n",
       "      <td>995</td>\n",
       "      <td>300</td>\n",
       "      <td>14.98</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "      <td>39.20</td>\n",
       "      <td>1.64</td>\n",
       "      <td>139.48</td>\n",
       "      <td>35.98</td>\n",
       "      <td>450.36</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>7.15</td>\n",
       "      <td>1115</td>\n",
       "      <td>300</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>48.24</td>\n",
       "      <td>1.51</td>\n",
       "      <td>67.33</td>\n",
       "      <td>63.21</td>\n",
       "      <td>450.36</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>7.65</td>\n",
       "      <td>2000</td>\n",
       "      <td>730</td>\n",
       "      <td>15.78</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>41.18</td>\n",
       "      <td>1.50</td>\n",
       "      <td>92.99</td>\n",
       "      <td>55.43</td>\n",
       "      <td>300.24</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>7.16</td>\n",
       "      <td>1120</td>\n",
       "      <td>340</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>44.54</td>\n",
       "      <td>1.54</td>\n",
       "      <td>96.19</td>\n",
       "      <td>59.32</td>\n",
       "      <td>450.36</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>7.27</td>\n",
       "      <td>775</td>\n",
       "      <td>230</td>\n",
       "      <td>14.98</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>37.80</td>\n",
       "      <td>0.74</td>\n",
       "      <td>121.84</td>\n",
       "      <td>24.31</td>\n",
       "      <td>450.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>7.12</td>\n",
       "      <td>1130</td>\n",
       "      <td>330</td>\n",
       "      <td>15.95</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>39.41</td>\n",
       "      <td>1.76</td>\n",
       "      <td>139.48</td>\n",
       "      <td>35.01</td>\n",
       "      <td>550.44</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>56</td>\n",
       "      <td>7.81</td>\n",
       "      <td>813</td>\n",
       "      <td>250</td>\n",
       "      <td>16.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.79</td>\n",
       "      <td>30.45</td>\n",
       "      <td>1.32</td>\n",
       "      <td>113.83</td>\n",
       "      <td>26.25</td>\n",
       "      <td>400.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>70</td>\n",
       "      <td>7.63</td>\n",
       "      <td>995</td>\n",
       "      <td>270</td>\n",
       "      <td>16.26</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>37.18</td>\n",
       "      <td>1.69</td>\n",
       "      <td>120.24</td>\n",
       "      <td>24.31</td>\n",
       "      <td>450.36</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>7.58</td>\n",
       "      <td>1226</td>\n",
       "      <td>330</td>\n",
       "      <td>15.32</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "      <td>33.09</td>\n",
       "      <td>0.81</td>\n",
       "      <td>89.78</td>\n",
       "      <td>35.98</td>\n",
       "      <td>300.24</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>7.64</td>\n",
       "      <td>964</td>\n",
       "      <td>290</td>\n",
       "      <td>14.29</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>27.71</td>\n",
       "      <td>1.12</td>\n",
       "      <td>113.83</td>\n",
       "      <td>34.03</td>\n",
       "      <td>400.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>7.36</td>\n",
       "      <td>773</td>\n",
       "      <td>230</td>\n",
       "      <td>15.37</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>37.30</td>\n",
       "      <td>1.09</td>\n",
       "      <td>115.43</td>\n",
       "      <td>22.56</td>\n",
       "      <td>350.28</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>8.09</td>\n",
       "      <td>432</td>\n",
       "      <td>140</td>\n",
       "      <td>14.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>36.61</td>\n",
       "      <td>1.64</td>\n",
       "      <td>64.13</td>\n",
       "      <td>16.53</td>\n",
       "      <td>400.32</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>7.84</td>\n",
       "      <td>549</td>\n",
       "      <td>170</td>\n",
       "      <td>13.78</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>34.96</td>\n",
       "      <td>1.74</td>\n",
       "      <td>64.13</td>\n",
       "      <td>7.81</td>\n",
       "      <td>300.24</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>7.92</td>\n",
       "      <td>560</td>\n",
       "      <td>160</td>\n",
       "      <td>12.98</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>39.28</td>\n",
       "      <td>1.35</td>\n",
       "      <td>52.91</td>\n",
       "      <td>3.89</td>\n",
       "      <td>300.24</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>7.94</td>\n",
       "      <td>806</td>\n",
       "      <td>240</td>\n",
       "      <td>11.90</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>38.13</td>\n",
       "      <td>1.16</td>\n",
       "      <td>80.16</td>\n",
       "      <td>8.75</td>\n",
       "      <td>500.40</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>7.70</td>\n",
       "      <td>765</td>\n",
       "      <td>220</td>\n",
       "      <td>12.89</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.65</td>\n",
       "      <td>31.31</td>\n",
       "      <td>1.71</td>\n",
       "      <td>101.00</td>\n",
       "      <td>2.92</td>\n",
       "      <td>450.36</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>7.99</td>\n",
       "      <td>556</td>\n",
       "      <td>150</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>38.69</td>\n",
       "      <td>1.95</td>\n",
       "      <td>67.33</td>\n",
       "      <td>4.86</td>\n",
       "      <td>250.20</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>8.16</td>\n",
       "      <td>512</td>\n",
       "      <td>160</td>\n",
       "      <td>11.90</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>32.14</td>\n",
       "      <td>1.42</td>\n",
       "      <td>78.56</td>\n",
       "      <td>1.94</td>\n",
       "      <td>300.24</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>8.05</td>\n",
       "      <td>536</td>\n",
       "      <td>150</td>\n",
       "      <td>10.92</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.55</td>\n",
       "      <td>36.59</td>\n",
       "      <td>1.24</td>\n",
       "      <td>54.51</td>\n",
       "      <td>13.61</td>\n",
       "      <td>200.16</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sample no  As    pH    EC   TDS     Cl   SO4   NO3    Fe    Mn     Na  \\\n",
       "0           1  25  6.90  2000   770  12.34  1.13  0.10  0.38  0.38  68.23   \n",
       "1           2  20  7.46   885   250  11.09  0.12  0.07  0.29  0.79  40.14   \n",
       "2           3  50  7.95   890   210  14.11  0.07  0.04  0.44  0.74  32.79   \n",
       "3           4  10  7.02   828   250  13.94  0.11  0.06  0.52  0.52  22.38   \n",
       "4           5  23  7.35   905   240  12.74  0.76  0.61  0.01  0.01  33.22   \n",
       "5           6  27  7.05  1043   320  13.29  0.18  0.13  0.24  0.80  40.00   \n",
       "6           7  18  7.44   642   200  14.04  0.22  0.94  0.43  0.43  31.53   \n",
       "7           8  26  7.49   366   120  14.93  0.65  0.57  0.34  0.34  37.50   \n",
       "8           9  40  6.98  1270   380  14.73  0.34  0.27  0.32  0.32  35.56   \n",
       "9          10  27  6.99  1015   250  13.98  0.72  0.60  0.11  0.81  37.10   \n",
       "10         11  11  7.18   632   190  13.79  0.92  0.78  0.31  0.91  40.43   \n",
       "11         12  22  6.95   995   300  14.98  0.16  0.05  0.47  0.57  39.20   \n",
       "12         13  10  7.15  1115   300  15.21  0.29  0.23  0.14  0.14  48.24   \n",
       "13         14  77  7.65  2000   730  15.78  0.56  0.48  0.65  0.65  41.18   \n",
       "14         15  60  7.16  1120   340  15.21  0.19  0.12  0.59  0.79  44.54   \n",
       "15         16  50  7.27   775   230  14.98  0.81  0.74  0.44  0.44  37.80   \n",
       "16         17  46  7.12  1130   330  15.95  0.17  0.11  0.68  0.68  39.41   \n",
       "17         18  56  7.81   813   250  16.28  0.16  0.04  0.59  0.79  30.45   \n",
       "18         19  70  7.63   995   270  16.26  0.04  0.02  0.11  0.11  37.18   \n",
       "19         20  36  7.58  1226   330  15.32  0.26  0.14  0.21  0.21  33.09   \n",
       "20         21  31  7.64   964   290  14.29  0.12  0.08  0.45  0.45  27.71   \n",
       "21         22  35  7.36   773   230  15.37  0.13  0.05  0.55  0.55  37.30   \n",
       "22         23  22  8.09   432   140  14.79  0.81  0.69  0.31  0.31  36.61   \n",
       "23         24  10  7.84   549   170  13.78  0.62  0.52  0.85  0.85  34.96   \n",
       "24         25  12  7.92   560   160  12.98  0.13  0.06  0.50  0.50  39.28   \n",
       "25         26  30  7.94   806   240  11.90  0.60  0.45  0.22  0.20  38.13   \n",
       "26         27  23  7.70   765   220  12.89  0.15  0.10  0.13  0.65  31.31   \n",
       "27         28  19  7.99   556   150  12.36  0.52  0.45  0.09  0.05  38.69   \n",
       "28         29  25  8.16   512   160  11.90  0.19  0.10  0.11  0.13  32.14   \n",
       "29         30  29  8.05   536   150  10.92  0.09  0.04  0.31  0.55  36.59   \n",
       "\n",
       "       K      Ca      Mg    HCO3   PO4  As_binary  \n",
       "0   3.13  195.59  151.69  400.32  1.22          1  \n",
       "1   2.00   83.37   51.54  450.36  0.71          1  \n",
       "2   2.87   41.68   51.54  350.28  1.08          1  \n",
       "3   1.91   80.16   35.98  500.40  0.92          0  \n",
       "4   2.15  101.00   33.06  350.28  0.52          1  \n",
       "5   2.21  128.26   24.31  500.40  0.86          1  \n",
       "6   1.66  107.41   23.34  350.28  0.74          1  \n",
       "7   1.82   67.33   11.67  250.20  0.41          1  \n",
       "8   1.25  166.73   37.92  550.44  1.80          1  \n",
       "9   1.28   81.76   34.03  450.36  0.55          1  \n",
       "10  1.54   99.39   34.03  400.32  0.62          1  \n",
       "11  1.64  139.48   35.98  450.36  0.42          1  \n",
       "12  1.51   67.33   63.21  450.36  0.49          0  \n",
       "13  1.50   92.99   55.43  300.24  0.88          1  \n",
       "14  1.54   96.19   59.32  450.36  0.73          1  \n",
       "15  0.74  121.84   24.31  450.36  0.46          1  \n",
       "16  1.76  139.48   35.01  550.44  0.69          1  \n",
       "17  1.32  113.83   26.25  400.32  0.22          1  \n",
       "18  1.69  120.24   24.31  450.36  0.14          1  \n",
       "19  0.81   89.78   35.98  300.24  0.32          1  \n",
       "20  1.12  113.83   34.03  400.32  0.32          1  \n",
       "21  1.09  115.43   22.56  350.28  0.39          1  \n",
       "22  1.64   64.13   16.53  400.32  0.47          1  \n",
       "23  1.74   64.13    7.81  300.24  0.51          0  \n",
       "24  1.35   52.91    3.89  300.24  0.68          1  \n",
       "25  1.16   80.16    8.75  500.40  0.56          1  \n",
       "26  1.71  101.00    2.92  450.36  0.72          1  \n",
       "27  1.95   67.33    4.86  250.20  0.78          1  \n",
       "28  1.42   78.56    1.94  300.24  1.39          1  \n",
       "29  1.24   54.51   13.61  200.16  0.27          1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c0d7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop([\"As_binary\",\"Sample no\"],axis=1) #contain all  independent variable\n",
    "y=data[\"As_binary\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7c05123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16319464 0.03671884 0.03221036 0.0234693  0.03206968 0.06197225\n",
      " 0.04419802 0.13077821 0.05498989 0.16767606 0.02744311 0.07232707\n",
      " 0.04473062 0.05091802 0.05730394]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based clas\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=x.columns)\n",
    "feat_importances.nlargest(11).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef723451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify features and target variables\n",
    "features = [\"HCO3\", \"PH\", \"SO4\", \"NO3\", \"Fe\", \"Mn\", \"Na\", \"Ca\", \"Mg\", \"PO4\"] \n",
    "target_variable = [\"As\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a177bf6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;28mlen\u001b[39m(features) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(target_variable))\n\u001b[1;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdata(data, columns\u001b[38;5;241m=\u001b[39mfeatures \u001b[38;5;241m+\u001b[39m target_variable)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Generating correlation matrix\u001b[39;00m\n\u001b[0;32m     15\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcorr()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame containing the features and target_variable\n",
    "# For demonstration, I'll create a dummy DataFrame\n",
    "\n",
    "# Creating a dummy DataFrame with random data\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(100, len(features) + len(target_variable))\n",
    "df = pd.data(data, columns=features + target_variable)\n",
    "\n",
    "# Generating correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Selecting correlation values related to the target variable\n",
    "corr_with_target = corr_matrix[target_variable]\n",
    "\n",
    "# Plotting heatmap for correlation values\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_with_target, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Pearson Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ef0d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a subset of the dataframe with selected features\n",
    "selected_features = data[\"features\" ,\"target_variable\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ab9ffd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Calculate the Pearsion correlation matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m selected_features()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "#Calculate the Pearsion correlation matrix\n",
    "correlation_matrix = selected_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fbbfc0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['features', 'target_variable']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Check the shape of the correlation matrix\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2941383",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ab808ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Inconsistent shape between the condition and the input (got (2, 1) and (2,))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot a heatmap to visualize correlations\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(correlation_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m, linewidths\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.5\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPearson correlation map\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mC:\\MiniConda\\Lib\\site-packages\\seaborn\\matrix.py:446\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m plotter \u001b[38;5;241m=\u001b[39m _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0;32m    447\u001b[0m                       annot_kws, cbar, cbar_kws, xticklabels,\n\u001b[0;32m    448\u001b[0m                       yticklabels, mask)\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[0;32m    451\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[1;32mC:\\MiniConda\\Lib\\site-packages\\seaborn\\matrix.py:115\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Validate the mask and convert to DataFrame\u001b[39;00m\n\u001b[0;32m    113\u001b[0m mask \u001b[38;5;241m=\u001b[39m _matrix_mask(data, mask)\n\u001b[1;32m--> 115\u001b[0m plot_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mmasked_where(np\u001b[38;5;241m.\u001b[39masarray(mask), plot_data)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Get good names for the rows and columns\u001b[39;00m\n\u001b[0;32m    118\u001b[0m xtickevery \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\MiniConda\\Lib\\site-packages\\numpy\\ma\\core.py:1933\u001b[0m, in \u001b[0;36mmasked_where\u001b[1;34m(condition, a, copy)\u001b[0m\n\u001b[0;32m   1931\u001b[0m (cshape, ashape) \u001b[38;5;241m=\u001b[39m (cond\u001b[38;5;241m.\u001b[39mshape, a\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m   1932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cshape \u001b[38;5;129;01mand\u001b[39;00m cshape \u001b[38;5;241m!=\u001b[39m ashape:\n\u001b[1;32m-> 1933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInconsistent shape between the condition and the input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1934\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (cshape, ashape))\n\u001b[0;32m   1935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_mask\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1936\u001b[0m     cond \u001b[38;5;241m=\u001b[39m mask_or(cond, a\u001b[38;5;241m.\u001b[39m_mask)\n",
      "\u001b[1;31mIndexError\u001b[0m: Inconsistent shape between the condition and the input (got (2, 1) and (2,))"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a heatmap to visualize correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", linewidths=.5)\n",
    "plt.title(\"Pearson correlation map\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833813b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
