{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib  # Correct import for joblib\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final feature engineered data\n",
    "df_final = pd.read_csv('final_feature_engineered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Conc. Of  pH</th>\n",
       "      <th>EC</th>\n",
       "      <th>Bicarb</th>\n",
       "      <th>Chlor</th>\n",
       "      <th>Iron</th>\n",
       "      <th>Manganese</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Log_Arsenic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213766</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.181918</td>\n",
       "      <td>0.529605</td>\n",
       "      <td>0.937836</td>\n",
       "      <td>-0.897475</td>\n",
       "      <td>-0.332173</td>\n",
       "      <td>-0.199134</td>\n",
       "      <td>-0.990882</td>\n",
       "      <td>-0.718107</td>\n",
       "      <td>0.459290</td>\n",
       "      <td>2.712108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.198689</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.189731</td>\n",
       "      <td>0.521134</td>\n",
       "      <td>0.922757</td>\n",
       "      <td>-0.903200</td>\n",
       "      <td>-0.345305</td>\n",
       "      <td>-0.198272</td>\n",
       "      <td>-0.970444</td>\n",
       "      <td>-0.688951</td>\n",
       "      <td>0.477924</td>\n",
       "      <td>2.704008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194115</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.203582</td>\n",
       "      <td>0.512210</td>\n",
       "      <td>0.953746</td>\n",
       "      <td>-0.860840</td>\n",
       "      <td>-0.374221</td>\n",
       "      <td>-0.185931</td>\n",
       "      <td>-0.971685</td>\n",
       "      <td>-0.696098</td>\n",
       "      <td>0.463224</td>\n",
       "      <td>2.671262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204799</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.191872</td>\n",
       "      <td>0.549472</td>\n",
       "      <td>0.960658</td>\n",
       "      <td>-0.921168</td>\n",
       "      <td>-0.368752</td>\n",
       "      <td>-0.218919</td>\n",
       "      <td>-0.977194</td>\n",
       "      <td>-0.670931</td>\n",
       "      <td>0.455944</td>\n",
       "      <td>2.705551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.389907</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.409650</td>\n",
       "      <td>-0.473947</td>\n",
       "      <td>-0.564241</td>\n",
       "      <td>-1.396437</td>\n",
       "      <td>-0.353426</td>\n",
       "      <td>-0.788518</td>\n",
       "      <td>-1.319128</td>\n",
       "      <td>0.775543</td>\n",
       "      <td>-0.114794</td>\n",
       "      <td>2.811246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.389169</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.326212</td>\n",
       "      <td>-0.507226</td>\n",
       "      <td>-0.535738</td>\n",
       "      <td>-1.405846</td>\n",
       "      <td>-0.380960</td>\n",
       "      <td>-0.752810</td>\n",
       "      <td>-1.323950</td>\n",
       "      <td>0.745343</td>\n",
       "      <td>-0.129277</td>\n",
       "      <td>2.864956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.411476</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.329115</td>\n",
       "      <td>-0.501720</td>\n",
       "      <td>-0.586776</td>\n",
       "      <td>-1.402391</td>\n",
       "      <td>-0.333524</td>\n",
       "      <td>-0.767888</td>\n",
       "      <td>-1.328753</td>\n",
       "      <td>0.806713</td>\n",
       "      <td>-0.082678</td>\n",
       "      <td>2.827142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.402605</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.344410</td>\n",
       "      <td>-0.471387</td>\n",
       "      <td>-0.567157</td>\n",
       "      <td>-1.447269</td>\n",
       "      <td>-0.383242</td>\n",
       "      <td>-0.785012</td>\n",
       "      <td>-1.349649</td>\n",
       "      <td>0.768426</td>\n",
       "      <td>-0.097811</td>\n",
       "      <td>2.847875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.403965</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.961438</td>\n",
       "      <td>-0.985865</td>\n",
       "      <td>-0.578515</td>\n",
       "      <td>0.501863</td>\n",
       "      <td>0.153439</td>\n",
       "      <td>-0.944401</td>\n",
       "      <td>0.111024</td>\n",
       "      <td>-1.265145</td>\n",
       "      <td>0.378072</td>\n",
       "      <td>3.250715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.443295</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-1.030846</td>\n",
       "      <td>-0.980619</td>\n",
       "      <td>-0.570541</td>\n",
       "      <td>0.514483</td>\n",
       "      <td>0.135911</td>\n",
       "      <td>-0.975615</td>\n",
       "      <td>0.153014</td>\n",
       "      <td>-1.301238</td>\n",
       "      <td>0.385498</td>\n",
       "      <td>3.235086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.348919</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.987501</td>\n",
       "      <td>-1.009261</td>\n",
       "      <td>-0.564257</td>\n",
       "      <td>0.500792</td>\n",
       "      <td>0.116623</td>\n",
       "      <td>-0.960404</td>\n",
       "      <td>0.108902</td>\n",
       "      <td>-1.306280</td>\n",
       "      <td>0.404702</td>\n",
       "      <td>3.283278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.413506</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.980599</td>\n",
       "      <td>-0.977828</td>\n",
       "      <td>-0.536462</td>\n",
       "      <td>0.554115</td>\n",
       "      <td>0.160662</td>\n",
       "      <td>-0.945686</td>\n",
       "      <td>0.142984</td>\n",
       "      <td>-1.325308</td>\n",
       "      <td>0.406172</td>\n",
       "      <td>3.241119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.191048</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.742132</td>\n",
       "      <td>0.722244</td>\n",
       "      <td>-0.551269</td>\n",
       "      <td>0.298711</td>\n",
       "      <td>-0.231366</td>\n",
       "      <td>0.086939</td>\n",
       "      <td>1.385282</td>\n",
       "      <td>-0.790186</td>\n",
       "      <td>0.511498</td>\n",
       "      <td>3.298366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.163172</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.765892</td>\n",
       "      <td>0.766761</td>\n",
       "      <td>-0.572920</td>\n",
       "      <td>0.248559</td>\n",
       "      <td>-0.290601</td>\n",
       "      <td>0.124875</td>\n",
       "      <td>1.418864</td>\n",
       "      <td>-0.782977</td>\n",
       "      <td>0.490790</td>\n",
       "      <td>3.230656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.148418</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.714796</td>\n",
       "      <td>0.699271</td>\n",
       "      <td>-0.543553</td>\n",
       "      <td>0.316503</td>\n",
       "      <td>-0.267457</td>\n",
       "      <td>0.089889</td>\n",
       "      <td>1.387848</td>\n",
       "      <td>-0.831066</td>\n",
       "      <td>0.518893</td>\n",
       "      <td>3.259957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.139837</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.772794</td>\n",
       "      <td>0.745214</td>\n",
       "      <td>-0.602549</td>\n",
       "      <td>0.321087</td>\n",
       "      <td>-0.225028</td>\n",
       "      <td>0.104677</td>\n",
       "      <td>1.387150</td>\n",
       "      <td>-0.807854</td>\n",
       "      <td>0.515434</td>\n",
       "      <td>3.249262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.216617</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>1.442548</td>\n",
       "      <td>-1.181108</td>\n",
       "      <td>-0.547141</td>\n",
       "      <td>-0.492377</td>\n",
       "      <td>-0.176832</td>\n",
       "      <td>0.877526</td>\n",
       "      <td>-0.718272</td>\n",
       "      <td>-0.254101</td>\n",
       "      <td>-0.339829</td>\n",
       "      <td>4.245306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.224547</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>1.524893</td>\n",
       "      <td>-1.220027</td>\n",
       "      <td>-0.610562</td>\n",
       "      <td>-0.460338</td>\n",
       "      <td>-0.153983</td>\n",
       "      <td>0.833477</td>\n",
       "      <td>-0.699742</td>\n",
       "      <td>-0.253327</td>\n",
       "      <td>-0.309917</td>\n",
       "      <td>4.265209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.204835</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>1.480022</td>\n",
       "      <td>-1.204236</td>\n",
       "      <td>-0.546412</td>\n",
       "      <td>-0.415926</td>\n",
       "      <td>-0.189666</td>\n",
       "      <td>0.831714</td>\n",
       "      <td>-0.710541</td>\n",
       "      <td>-0.255480</td>\n",
       "      <td>-0.349488</td>\n",
       "      <td>4.247390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.176050</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>1.443563</td>\n",
       "      <td>-1.194565</td>\n",
       "      <td>-0.568110</td>\n",
       "      <td>-0.500286</td>\n",
       "      <td>-0.205625</td>\n",
       "      <td>0.816156</td>\n",
       "      <td>-0.731213</td>\n",
       "      <td>-0.279034</td>\n",
       "      <td>-0.346970</td>\n",
       "      <td>4.236032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.176482</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>1.484093</td>\n",
       "      <td>-1.150029</td>\n",
       "      <td>-0.490397</td>\n",
       "      <td>-0.412671</td>\n",
       "      <td>-0.211854</td>\n",
       "      <td>0.847092</td>\n",
       "      <td>-0.735555</td>\n",
       "      <td>-0.271758</td>\n",
       "      <td>-0.345410</td>\n",
       "      <td>4.255993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.648966</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-2.492794</td>\n",
       "      <td>1.620694</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>2.213489</td>\n",
       "      <td>1.216120</td>\n",
       "      <td>0.605988</td>\n",
       "      <td>0.736430</td>\n",
       "      <td>1.313136</td>\n",
       "      <td>1.214296</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.648966</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.910556</td>\n",
       "      <td>0.061813</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>1.875330</td>\n",
       "      <td>2.533678</td>\n",
       "      <td>1.498620</td>\n",
       "      <td>0.865038</td>\n",
       "      <td>-0.056871</td>\n",
       "      <td>1.368144</td>\n",
       "      <td>1.945910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.648966</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-1.474684</td>\n",
       "      <td>1.511905</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>0.163654</td>\n",
       "      <td>1.911760</td>\n",
       "      <td>3.888941</td>\n",
       "      <td>-0.097930</td>\n",
       "      <td>-0.210933</td>\n",
       "      <td>0.953491</td>\n",
       "      <td>2.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.156934</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-1.727366</td>\n",
       "      <td>2.376656</td>\n",
       "      <td>2.316229</td>\n",
       "      <td>-1.004502</td>\n",
       "      <td>-1.149010</td>\n",
       "      <td>1.386235</td>\n",
       "      <td>-0.648833</td>\n",
       "      <td>1.196789</td>\n",
       "      <td>1.608201</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.156934</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.972938</td>\n",
       "      <td>-0.380401</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>0.628290</td>\n",
       "      <td>2.370488</td>\n",
       "      <td>-0.274624</td>\n",
       "      <td>1.795109</td>\n",
       "      <td>0.376643</td>\n",
       "      <td>1.007188</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.156934</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.321770</td>\n",
       "      <td>0.315978</td>\n",
       "      <td>2.316229</td>\n",
       "      <td>0.966982</td>\n",
       "      <td>-1.301602</td>\n",
       "      <td>-1.178592</td>\n",
       "      <td>1.986566</td>\n",
       "      <td>-0.483373</td>\n",
       "      <td>1.375757</td>\n",
       "      <td>1.945910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.156934</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.806712</td>\n",
       "      <td>0.284894</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>-0.131904</td>\n",
       "      <td>-1.099014</td>\n",
       "      <td>-0.431062</td>\n",
       "      <td>2.115548</td>\n",
       "      <td>2.055641</td>\n",
       "      <td>1.411283</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.156934</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.746339</td>\n",
       "      <td>0.703670</td>\n",
       "      <td>-0.558956</td>\n",
       "      <td>0.300733</td>\n",
       "      <td>-0.265015</td>\n",
       "      <td>0.112192</td>\n",
       "      <td>1.397733</td>\n",
       "      <td>-0.814273</td>\n",
       "      <td>0.510234</td>\n",
       "      <td>3.258097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.685845</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.106261</td>\n",
       "      <td>1.169755</td>\n",
       "      <td>-0.558956</td>\n",
       "      <td>0.361073</td>\n",
       "      <td>-1.405577</td>\n",
       "      <td>-0.152641</td>\n",
       "      <td>-0.172895</td>\n",
       "      <td>1.615090</td>\n",
       "      <td>-2.015707</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.685845</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.290777</td>\n",
       "      <td>1.090550</td>\n",
       "      <td>-0.558956</td>\n",
       "      <td>0.945695</td>\n",
       "      <td>-0.094729</td>\n",
       "      <td>-1.919036</td>\n",
       "      <td>0.262016</td>\n",
       "      <td>-1.255074</td>\n",
       "      <td>-2.109886</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.685845</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.199831</td>\n",
       "      <td>1.375127</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>2.528674</td>\n",
       "      <td>-0.621152</td>\n",
       "      <td>-0.964301</td>\n",
       "      <td>1.150713</td>\n",
       "      <td>1.669452</td>\n",
       "      <td>-2.164018</td>\n",
       "      <td>1.945910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.200140</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>1.466277</td>\n",
       "      <td>-0.710772</td>\n",
       "      <td>-2.321421</td>\n",
       "      <td>1.315407</td>\n",
       "      <td>3.496431</td>\n",
       "      <td>0.054447</td>\n",
       "      <td>0.256990</td>\n",
       "      <td>1.313136</td>\n",
       "      <td>-2.417841</td>\n",
       "      <td>1.791759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.200140</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.414149</td>\n",
       "      <td>-0.983449</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>1.281093</td>\n",
       "      <td>-1.301602</td>\n",
       "      <td>1.542931</td>\n",
       "      <td>0.503957</td>\n",
       "      <td>-0.056871</td>\n",
       "      <td>-1.787148</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.200140</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.910556</td>\n",
       "      <td>-0.864792</td>\n",
       "      <td>-0.558956</td>\n",
       "      <td>1.281093</td>\n",
       "      <td>-0.052918</td>\n",
       "      <td>0.197674</td>\n",
       "      <td>0.290378</td>\n",
       "      <td>0.510738</td>\n",
       "      <td>-1.818107</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.200140</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>1.466277</td>\n",
       "      <td>-1.187583</td>\n",
       "      <td>-0.558956</td>\n",
       "      <td>-0.452516</td>\n",
       "      <td>-0.179255</td>\n",
       "      <td>0.837001</td>\n",
       "      <td>-0.722203</td>\n",
       "      <td>-0.263225</td>\n",
       "      <td>-0.333494</td>\n",
       "      <td>4.262680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.200140</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-1.537740</td>\n",
       "      <td>-0.598246</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>-0.927457</td>\n",
       "      <td>-0.951530</td>\n",
       "      <td>-0.791968</td>\n",
       "      <td>-0.231250</td>\n",
       "      <td>1.965466</td>\n",
       "      <td>0.210747</td>\n",
       "      <td>2.397895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.200140</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.260836</td>\n",
       "      <td>-0.344985</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>-0.526058</td>\n",
       "      <td>0.976312</td>\n",
       "      <td>-0.243870</td>\n",
       "      <td>-0.131073</td>\n",
       "      <td>1.953598</td>\n",
       "      <td>-0.814552</td>\n",
       "      <td>2.484907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.200140</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.927251</td>\n",
       "      <td>2.314296</td>\n",
       "      <td>-2.321421</td>\n",
       "      <td>-0.775083</td>\n",
       "      <td>0.726297</td>\n",
       "      <td>0.911872</td>\n",
       "      <td>-0.455558</td>\n",
       "      <td>-0.210933</td>\n",
       "      <td>-0.313233</td>\n",
       "      <td>2.197225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.200140</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>0.199831</td>\n",
       "      <td>0.528402</td>\n",
       "      <td>0.968468</td>\n",
       "      <td>-0.910414</td>\n",
       "      <td>-0.352046</td>\n",
       "      <td>-0.213290</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>-0.687144</td>\n",
       "      <td>0.467966</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.408857</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.352427</td>\n",
       "      <td>-0.488156</td>\n",
       "      <td>-0.558956</td>\n",
       "      <td>-1.398669</td>\n",
       "      <td>-0.352046</td>\n",
       "      <td>-0.791968</td>\n",
       "      <td>-1.321218</td>\n",
       "      <td>0.774710</td>\n",
       "      <td>-0.113919</td>\n",
       "      <td>2.833213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.408857</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-8.881784e-16</td>\n",
       "      <td>-0.972938</td>\n",
       "      <td>-0.983449</td>\n",
       "      <td>-0.558956</td>\n",
       "      <td>0.525199</td>\n",
       "      <td>0.151788</td>\n",
       "      <td>-0.964301</td>\n",
       "      <td>0.128349</td>\n",
       "      <td>-1.303884</td>\n",
       "      <td>0.409331</td>\n",
       "      <td>3.258097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Day         Month          Year  Conc. Of  pH        EC    Bicarb  \\\n",
       "0   0.213766  1.110223e-16 -8.881784e-16      0.181918  0.529605  0.937836   \n",
       "1   0.198689  1.110223e-16 -8.881784e-16      0.189731  0.521134  0.922757   \n",
       "2   0.194115  1.110223e-16 -8.881784e-16      0.203582  0.512210  0.953746   \n",
       "3   0.204799  1.110223e-16 -8.881784e-16      0.191872  0.549472  0.960658   \n",
       "4   1.389907  1.110223e-16 -8.881784e-16     -0.409650 -0.473947 -0.564241   \n",
       "5   1.389169  1.110223e-16 -8.881784e-16     -0.326212 -0.507226 -0.535738   \n",
       "6   1.411476  1.110223e-16 -8.881784e-16     -0.329115 -0.501720 -0.586776   \n",
       "7   1.402605  1.110223e-16 -8.881784e-16     -0.344410 -0.471387 -0.567157   \n",
       "8   1.403965  1.110223e-16 -8.881784e-16     -0.961438 -0.985865 -0.578515   \n",
       "9   1.443295  1.110223e-16 -8.881784e-16     -1.030846 -0.980619 -0.570541   \n",
       "10  1.348919  1.110223e-16 -8.881784e-16     -0.987501 -1.009261 -0.564257   \n",
       "11  1.413506  1.110223e-16 -8.881784e-16     -0.980599 -0.977828 -0.536462   \n",
       "12 -1.191048  1.110223e-16 -8.881784e-16      0.742132  0.722244 -0.551269   \n",
       "13 -1.163172  1.110223e-16 -8.881784e-16      0.765892  0.766761 -0.572920   \n",
       "14 -1.148418  1.110223e-16 -8.881784e-16      0.714796  0.699271 -0.543553   \n",
       "15 -1.139837  1.110223e-16 -8.881784e-16      0.772794  0.745214 -0.602549   \n",
       "16  0.216617  1.110223e-16 -8.881784e-16      1.442548 -1.181108 -0.547141   \n",
       "17  0.224547  1.110223e-16 -8.881784e-16      1.524893 -1.220027 -0.610562   \n",
       "18  0.204835  1.110223e-16 -8.881784e-16      1.480022 -1.204236 -0.546412   \n",
       "19  0.176050  1.110223e-16 -8.881784e-16      1.443563 -1.194565 -0.568110   \n",
       "20  0.176482  1.110223e-16 -8.881784e-16      1.484093 -1.150029 -0.490397   \n",
       "21 -1.648966  1.110223e-16 -8.881784e-16     -2.492794  1.620694  0.968468   \n",
       "22 -1.648966  1.110223e-16 -8.881784e-16     -0.910556  0.061813  0.968468   \n",
       "23 -1.648966  1.110223e-16 -8.881784e-16     -1.474684  1.511905  0.968468   \n",
       "24 -1.156934  1.110223e-16 -8.881784e-16     -1.727366  2.376656  2.316229   \n",
       "25 -1.156934  1.110223e-16 -8.881784e-16     -0.972938 -0.380401  0.968468   \n",
       "26 -1.156934  1.110223e-16 -8.881784e-16      0.321770  0.315978  2.316229   \n",
       "27 -1.156934  1.110223e-16 -8.881784e-16      0.806712  0.284894  0.968468   \n",
       "28 -1.156934  1.110223e-16 -8.881784e-16      0.746339  0.703670 -0.558956   \n",
       "29 -0.685845  1.110223e-16 -8.881784e-16     -0.106261  1.169755 -0.558956   \n",
       "30 -0.685845  1.110223e-16 -8.881784e-16     -0.290777  1.090550 -0.558956   \n",
       "31 -0.685845  1.110223e-16 -8.881784e-16      0.199831  1.375127  0.968468   \n",
       "32  0.200140  1.110223e-16 -8.881784e-16      1.466277 -0.710772 -2.321421   \n",
       "33  0.200140  1.110223e-16 -8.881784e-16     -0.414149 -0.983449  0.968468   \n",
       "34  0.200140  1.110223e-16 -8.881784e-16     -0.910556 -0.864792 -0.558956   \n",
       "35  0.200140  1.110223e-16 -8.881784e-16      1.466277 -1.187583 -0.558956   \n",
       "36  0.200140  1.110223e-16 -8.881784e-16     -1.537740 -0.598246  0.968468   \n",
       "37  0.200140  1.110223e-16 -8.881784e-16      0.260836 -0.344985  0.968468   \n",
       "38  0.200140  1.110223e-16 -8.881784e-16      0.927251  2.314296 -2.321421   \n",
       "39  0.200140  1.110223e-16 -8.881784e-16      0.199831  0.528402  0.968468   \n",
       "40  1.408857  1.110223e-16 -8.881784e-16     -0.352427 -0.488156 -0.558956   \n",
       "41  1.408857  1.110223e-16 -8.881784e-16     -0.972938 -0.983449 -0.558956   \n",
       "\n",
       "       Chlor      Iron  Manganese    Sodium  Potassium  Magnesium  Log_Arsenic  \n",
       "0  -0.897475 -0.332173  -0.199134 -0.990882  -0.718107   0.459290     2.712108  \n",
       "1  -0.903200 -0.345305  -0.198272 -0.970444  -0.688951   0.477924     2.704008  \n",
       "2  -0.860840 -0.374221  -0.185931 -0.971685  -0.696098   0.463224     2.671262  \n",
       "3  -0.921168 -0.368752  -0.218919 -0.977194  -0.670931   0.455944     2.705551  \n",
       "4  -1.396437 -0.353426  -0.788518 -1.319128   0.775543  -0.114794     2.811246  \n",
       "5  -1.405846 -0.380960  -0.752810 -1.323950   0.745343  -0.129277     2.864956  \n",
       "6  -1.402391 -0.333524  -0.767888 -1.328753   0.806713  -0.082678     2.827142  \n",
       "7  -1.447269 -0.383242  -0.785012 -1.349649   0.768426  -0.097811     2.847875  \n",
       "8   0.501863  0.153439  -0.944401  0.111024  -1.265145   0.378072     3.250715  \n",
       "9   0.514483  0.135911  -0.975615  0.153014  -1.301238   0.385498     3.235086  \n",
       "10  0.500792  0.116623  -0.960404  0.108902  -1.306280   0.404702     3.283278  \n",
       "11  0.554115  0.160662  -0.945686  0.142984  -1.325308   0.406172     3.241119  \n",
       "12  0.298711 -0.231366   0.086939  1.385282  -0.790186   0.511498     3.298366  \n",
       "13  0.248559 -0.290601   0.124875  1.418864  -0.782977   0.490790     3.230656  \n",
       "14  0.316503 -0.267457   0.089889  1.387848  -0.831066   0.518893     3.259957  \n",
       "15  0.321087 -0.225028   0.104677  1.387150  -0.807854   0.515434     3.249262  \n",
       "16 -0.492377 -0.176832   0.877526 -0.718272  -0.254101  -0.339829     4.245306  \n",
       "17 -0.460338 -0.153983   0.833477 -0.699742  -0.253327  -0.309917     4.265209  \n",
       "18 -0.415926 -0.189666   0.831714 -0.710541  -0.255480  -0.349488     4.247390  \n",
       "19 -0.500286 -0.205625   0.816156 -0.731213  -0.279034  -0.346970     4.236032  \n",
       "20 -0.412671 -0.211854   0.847092 -0.735555  -0.271758  -0.345410     4.255993  \n",
       "21  2.213489  1.216120   0.605988  0.736430   1.313136   1.214296     1.386294  \n",
       "22  1.875330  2.533678   1.498620  0.865038  -0.056871   1.368144     1.945910  \n",
       "23  0.163654  1.911760   3.888941 -0.097930  -0.210933   0.953491     2.079442  \n",
       "24 -1.004502 -1.149010   1.386235 -0.648833   1.196789   1.608201     1.098612  \n",
       "25  0.628290  2.370488  -0.274624  1.795109   0.376643   1.007188     1.609438  \n",
       "26  0.966982 -1.301602  -1.178592  1.986566  -0.483373   1.375757     1.945910  \n",
       "27 -0.131904 -1.099014  -0.431062  2.115548   2.055641   1.411283     1.609438  \n",
       "28  0.300733 -0.265015   0.112192  1.397733  -0.814273   0.510234     3.258097  \n",
       "29  0.361073 -1.405577  -0.152641 -0.172895   1.615090  -2.015707     1.609438  \n",
       "30  0.945695 -0.094729  -1.919036  0.262016  -1.255074  -2.109886     1.098612  \n",
       "31  2.528674 -0.621152  -0.964301  1.150713   1.669452  -2.164018     1.945910  \n",
       "32  1.315407  3.496431   0.054447  0.256990   1.313136  -2.417841     1.791759  \n",
       "33  1.281093 -1.301602   1.542931  0.503957  -0.056871  -1.787148     1.098612  \n",
       "34  1.281093 -0.052918   0.197674  0.290378   0.510738  -1.818107     1.609438  \n",
       "35 -0.452516 -0.179255   0.837001 -0.722203  -0.263225  -0.333494     4.262680  \n",
       "36 -0.927457 -0.951530  -0.791968 -0.231250   1.965466   0.210747     2.397895  \n",
       "37 -0.526058  0.976312  -0.243870 -0.131073   1.953598  -0.814552     2.484907  \n",
       "38 -0.775083  0.726297   0.911872 -0.455558  -0.210933  -0.313233     2.197225  \n",
       "39 -0.910414 -0.352046  -0.213290 -0.975926  -0.687144   0.467966     2.708050  \n",
       "40 -1.398669 -0.352046  -0.791968 -1.321218   0.774710  -0.113919     2.833213  \n",
       "41  0.525199  0.151788  -0.964301  0.128349  -1.303884   0.409331     3.258097  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining The dependent and indepedent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and target\n",
    "X = df_final.drop(columns=['Log_Arsenic'])\n",
    "y = df_final['Log_Arsenic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling for the final time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Linear Regression\", LinearRegression()),\n",
    "    (\"Polynomial Regression\", PolynomialFeatures(degree=2)),  # This will need to be handled specially\n",
    "    (\"Ridge Regression\", Ridge()),\n",
    "    (\"Lasso Regression\", Lasso()),\n",
    "    (\"Elastic Net Regression\", ElasticNet()),\n",
    "    (\"Support Vector Regression\", SVR()),\n",
    "    (\"Decision Tree Regression\", DecisionTreeRegressor()),\n",
    "    (\"Random Forest Regression\", RandomForestRegressor(random_state=42)),\n",
    "    (\"Gradient Boosting Regression\", GradientBoostingRegressor(random_state=42)),\n",
    "    (\"K-Nearest Neighbors Regression\", KNeighborsRegressor()),\n",
    "    (\"Bayesian Regression\", BayesianRidge()),\n",
    "    (\"Neural Network Regression\", MLPRegressor(hidden_layer_sizes=(50,50,50), max_iter=1000, random_state=42)),\n",
    "    (\"Principal Component Regression (PCR)\", make_pipeline(StandardScaler(), PCA(), LinearRegression())),\n",
    "    (\"Partial Least Squares Regression (PLS)\", PLSRegression())\n",
    "]\n",
    "# Define evaluation metrics\n",
    "metrics = {\n",
    "    \"MAE\": mean_absolute_error,\n",
    "    \"MSE\": mean_squared_error,\n",
    "    \"R2\": r2_score\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the k-fold validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression...\n",
      "Evaluating Polynomial Regression...\n",
      "Evaluating Ridge Regression...\n",
      "Evaluating Lasso Regression...\n",
      "Evaluating Elastic Net Regression...\n",
      "Evaluating Support Vector Regression...\n",
      "Evaluating Decision Tree Regression...\n",
      "Evaluating Random Forest Regression...\n",
      "Evaluating Gradient Boosting Regression...\n",
      "Evaluating K-Nearest Neighbors Regression...\n",
      "Evaluating Bayesian Regression...\n",
      "Evaluating Neural Network Regression...\n",
      "Evaluating Principal Component Regression (PCR)...\n",
      "Evaluating Partial Least Squares Regression (PLS)...\n",
      "                                        CV_R2_Score           MAE  \\\n",
      "Linear Regression                          0.167647  4.561923e-01   \n",
      "Polynomial Regression                      0.217806  9.128500e-16   \n",
      "Ridge Regression                           0.317766  4.289743e-01   \n",
      "Lasso Regression                          -0.311644  8.133298e-01   \n",
      "Elastic Net Regression                    -0.288568  8.092209e-01   \n",
      "Support Vector Regression                  0.846930  2.720220e-01   \n",
      "Decision Tree Regression                   0.258534  4.560451e-01   \n",
      "Random Forest Regression                   0.634661  4.198173e-01   \n",
      "Gradient Boosting Regression               0.647519  4.061689e-01   \n",
      "K-Nearest Neighbors Regression            -0.032279  4.831339e-01   \n",
      "Bayesian Regression                        0.332541  4.352065e-01   \n",
      "Neural Network Regression                  0.377827  4.236287e-01   \n",
      "Principal Component Regression (PCR)       0.167647  2.062382e-01   \n",
      "Partial Least Squares Regression (PLS)     0.348971  3.848405e-01   \n",
      "\n",
      "                                                 MSE        R2  \n",
      "Linear Regression                       4.337293e-01  0.518584  \n",
      "Polynomial Regression                   1.922848e-30  1.000000  \n",
      "Ridge Regression                        3.494912e-01  0.612083  \n",
      "Lasso Regression                        9.699867e-01 -0.076633  \n",
      "Elastic Net Regression                  9.534373e-01 -0.058264  \n",
      "Support Vector Regression               1.931032e-01  0.785666  \n",
      "Decision Tree Regression                7.352958e-01  0.183861  \n",
      "Random Forest Regression                5.731295e-01  0.363857  \n",
      "Gradient Boosting Regression            6.423270e-01  0.287051  \n",
      "K-Nearest Neighbors Regression          6.104306e-01  0.322455  \n",
      "Bayesian Regression                     3.334634e-01  0.629874  \n",
      "Neural Network Regression               5.357772e-01  0.405316  \n",
      "Principal Component Regression (PCR)    7.345748e-02  0.918466  \n",
      "Partial Least Squares Regression (PLS)  3.102032e-01  0.655691  \n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Iterate through the list of models\n",
    "for name, model in models:\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    \n",
    "    if name == \"Polynomial Regression\":\n",
    "        # Special handling for Polynomial Regression\n",
    "        poly = PolynomialFeatures(degree=2)\n",
    "        X_poly = poly.fit_transform(X_scaled)\n",
    "        lr = LinearRegression()\n",
    "        scores = cross_val_score(lr, X_poly, y, cv=kf, scoring='r2')\n",
    "        lr.fit(X_poly, y)\n",
    "        y_pred = lr.predict(poly.transform(X_test))\n",
    "        model = lr  # Update model to be the trained Linear Regression\n",
    "    elif name == \"Principal Component Regression (PCR)\":\n",
    "        # Special handling for PCR\n",
    "        pcr = make_pipeline(StandardScaler(), PCA(), LinearRegression())\n",
    "        scores = cross_val_score(pcr, X_scaled, y, cv=kf, scoring='r2')\n",
    "        pcr.fit(X_scaled, y)\n",
    "        y_pred = pcr.predict(X_test)\n",
    "        model = pcr  # Update model to be the trained pipeline\n",
    "    else:\n",
    "        # Standard handling for other models\n",
    "        scores = cross_val_score(model, X_scaled, y, cv=kf, scoring='r2')\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the results\n",
    "    results[name] = {\n",
    "        \"CV_R2_Score\": scores.mean(),\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"R2\": r2\n",
    "    }\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(model, f\"{name}.pkl\")\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('model_comparison_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here CV R2 Score means the k-fold cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_R2_Score</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.167647</td>\n",
       "      <td>4.561923e-01</td>\n",
       "      <td>4.337293e-01</td>\n",
       "      <td>0.518584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial Regression</th>\n",
       "      <td>0.217806</td>\n",
       "      <td>9.128500e-16</td>\n",
       "      <td>1.922848e-30</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>0.317766</td>\n",
       "      <td>4.289743e-01</td>\n",
       "      <td>3.494912e-01</td>\n",
       "      <td>0.612083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Regression</th>\n",
       "      <td>-0.311644</td>\n",
       "      <td>8.133298e-01</td>\n",
       "      <td>9.699867e-01</td>\n",
       "      <td>-0.076633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elastic Net Regression</th>\n",
       "      <td>-0.288568</td>\n",
       "      <td>8.092209e-01</td>\n",
       "      <td>9.534373e-01</td>\n",
       "      <td>-0.058264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Regression</th>\n",
       "      <td>0.846930</td>\n",
       "      <td>2.720220e-01</td>\n",
       "      <td>1.931032e-01</td>\n",
       "      <td>0.785666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Regression</th>\n",
       "      <td>0.258534</td>\n",
       "      <td>4.560451e-01</td>\n",
       "      <td>7.352958e-01</td>\n",
       "      <td>0.183861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Regression</th>\n",
       "      <td>0.634661</td>\n",
       "      <td>4.198173e-01</td>\n",
       "      <td>5.731295e-01</td>\n",
       "      <td>0.363857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Regression</th>\n",
       "      <td>0.647519</td>\n",
       "      <td>4.061689e-01</td>\n",
       "      <td>6.423270e-01</td>\n",
       "      <td>0.287051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors Regression</th>\n",
       "      <td>-0.032279</td>\n",
       "      <td>4.831339e-01</td>\n",
       "      <td>6.104306e-01</td>\n",
       "      <td>0.322455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Regression</th>\n",
       "      <td>0.332541</td>\n",
       "      <td>4.352065e-01</td>\n",
       "      <td>3.334634e-01</td>\n",
       "      <td>0.629874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network Regression</th>\n",
       "      <td>0.377827</td>\n",
       "      <td>4.236287e-01</td>\n",
       "      <td>5.357772e-01</td>\n",
       "      <td>0.405316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Principal Component Regression (PCR)</th>\n",
       "      <td>0.167647</td>\n",
       "      <td>2.062382e-01</td>\n",
       "      <td>7.345748e-02</td>\n",
       "      <td>0.918466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Partial Least Squares Regression (PLS)</th>\n",
       "      <td>0.348971</td>\n",
       "      <td>3.848405e-01</td>\n",
       "      <td>3.102032e-01</td>\n",
       "      <td>0.655691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        CV_R2_Score           MAE  \\\n",
       "Linear Regression                          0.167647  4.561923e-01   \n",
       "Polynomial Regression                      0.217806  9.128500e-16   \n",
       "Ridge Regression                           0.317766  4.289743e-01   \n",
       "Lasso Regression                          -0.311644  8.133298e-01   \n",
       "Elastic Net Regression                    -0.288568  8.092209e-01   \n",
       "Support Vector Regression                  0.846930  2.720220e-01   \n",
       "Decision Tree Regression                   0.258534  4.560451e-01   \n",
       "Random Forest Regression                   0.634661  4.198173e-01   \n",
       "Gradient Boosting Regression               0.647519  4.061689e-01   \n",
       "K-Nearest Neighbors Regression            -0.032279  4.831339e-01   \n",
       "Bayesian Regression                        0.332541  4.352065e-01   \n",
       "Neural Network Regression                  0.377827  4.236287e-01   \n",
       "Principal Component Regression (PCR)       0.167647  2.062382e-01   \n",
       "Partial Least Squares Regression (PLS)     0.348971  3.848405e-01   \n",
       "\n",
       "                                                 MSE        R2  \n",
       "Linear Regression                       4.337293e-01  0.518584  \n",
       "Polynomial Regression                   1.922848e-30  1.000000  \n",
       "Ridge Regression                        3.494912e-01  0.612083  \n",
       "Lasso Regression                        9.699867e-01 -0.076633  \n",
       "Elastic Net Regression                  9.534373e-01 -0.058264  \n",
       "Support Vector Regression               1.931032e-01  0.785666  \n",
       "Decision Tree Regression                7.352958e-01  0.183861  \n",
       "Random Forest Regression                5.731295e-01  0.363857  \n",
       "Gradient Boosting Regression            6.423270e-01  0.287051  \n",
       "K-Nearest Neighbors Regression          6.104306e-01  0.322455  \n",
       "Bayesian Regression                     3.334634e-01  0.629874  \n",
       "Neural Network Regression               5.357772e-01  0.405316  \n",
       "Principal Component Regression (PCR)    7.345748e-02  0.918466  \n",
       "Partial Least Squares Regression (PLS)  3.102032e-01  0.655691  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OutPut Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    " ### Polynomial Regression:\n",
    "\n",
    "R2: 1.0, indicating a perfect fit on the test data.\n",
    "MAE & MSE: Extremely low values (close to zero), indicating very accurate predictions.\n",
    "Note: This may suggest overfitting, especially if the cross-validation score is not similarly high.\n",
    "\n",
    " ### Support Vector Regression (SVR):\n",
    "\n",
    "CV_R2_Score: 0.847, the highest among all models.\n",
    "R2: 0.786, indicating strong performance on the test data.\n",
    "MAE & MSE: Low values, indicating good prediction accuracy.\n",
    "\n",
    " ### Ridge Regression:\n",
    "\n",
    "CV_R2_Score: 0.318, better than simple linear regression.\n",
    "R2: 0.612, indicating decent performance on the test data.\n",
    "MAE & MSE: Improved over linear regression.\n",
    "\n",
    " ### Lasso and Elastic Net Regression:\n",
    "\n",
    "CV_R2_Score: Negative values, indicating poor performance during cross-validation.\n",
    "R2: Negative and close to zero, indicating poor performance on the test data.\n",
    "\n",
    " ### Random Forest Regression:\n",
    "\n",
    "CV_R2_Score: 0.635, indicating good performance during cross-validation.\n",
    "R2: 0.364, lower than expected performance on the test data.\n",
    "\n",
    " ### Gradient Boosting Regression:\n",
    "\n",
    "CV_R2_Score: 0.648, indicating good performance during cross-validation.\n",
    "R2: 0.287, indicating moderate performance on the test data.\n",
    " \n",
    " ### Principal Component Regression (PCR):\n",
    "\n",
    "R2: 0.918, indicating very strong performance on the test data.\n",
    "CV_R2_Score: 0.168, indicating potential overfitting.\n",
    " \n",
    " ### K-Nearest Neighbors Regression:\n",
    "\n",
    "CV_R2_Score: Negative value, indicating poor performance during cross-validation.\n",
    "R2: 0.322, indicating moderate performance on the test data.\n",
    " \n",
    " ### Neural Network Regression:\n",
    "\n",
    "CV_R2_Score: 0.378, indicating decent performance during cross-validation.\n",
    "R2: 0.405, indicating decent performance on the test data.\n",
    " \n",
    " ### Bayesian Regression:\n",
    "\n",
    "CV_R2_Score: 0.333, indicating decent performance during cross-validation.\n",
    "R2: 0.630, indicating good performance on the test data.\n",
    " \n",
    " ### Partial Least Squares Regression (PLS):\n",
    "\n",
    "CV_R2_Score: 0.349, indicating decent performance during cross-validation.\n",
    "R2: 0.656, indicating good performance on the test data.\n",
    " \n",
    "## Conclusion:\n",
    "\n",
    " ### Best Performing Models:\n",
    "\n",
    "Polynomial Regression and Support Vector Regression (SVR) show the best performance on the test data with very high R² scores.\n",
    "PCR also shows a high R² score, but its cross-validation score suggests potential overfitting.\n",
    "\n",
    " ### Moderately Performing Models:\n",
    "\n",
    "Ridge Regression, Bayesian Regression, and PLS show good performance with reasonable R² scores.\n",
    "Poor Performing Models:\n",
    "\n",
    "Lasso Regression, Elastic Net Regression, and K-Nearest Neighbors Regression show poor performance with negative or low R² scores.\n",
    "\n",
    "### Caution with Overfitting:\n",
    "\n",
    "Polynomial Regression shows perfect fit on the test data but might be overfitting, as indicated by the disparity between its cross-validation score and test score.\n",
    "PCR shows high test performance but much lower cross-validation performance, suggesting overfitting.\n",
    "Given the results, Support Vector Regression (SVR) appears to be the most reliable model with consistently high performance across both cross-validation and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Cross Validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Support Vector Regression (SVR):\n",
    "\n",
    "CV_R2_Score: 0.846930 (high cross-validation score, indicating strong performance across folds)\n",
    "R2: 0.785666 (high test score, indicating consistent performance on unseen data)\n",
    "\n",
    "## Ridge Regression:\n",
    "\n",
    "CV_R2_Score: 0.317766 (moderate cross-validation score)\n",
    "R2: 0.612083 (good test score, indicating improved performance over linear regression)\n",
    "\n",
    "## Polynomial Regression:\n",
    "\n",
    "CV_R2_Score: 0.217806 (moderate cross-validation score, indicating potential overfitting)\n",
    "R2: 1.000000 (perfect test score, likely overfitting)\n",
    "\n",
    "## Principal Component Regression (PCR):\n",
    "\n",
    "CV_R2_Score: 0.167647 (moderate cross-validation score)\n",
    "R2: 0.918466 (high test score, indicating potential overfitting)\n",
    "\n",
    "## Recommendations:\n",
    "\n",
    "High Performing Models: SVR, Ridge Regression, and Bayesian Regression are strong candidates for further tuning and deployment due to their consistent performance.\n",
    "\n",
    "Overfitting Concerns: Polynomial Regression and PCR show signs of overfitting despite their high test scores. These models should be used cautiously.\n",
    "\n",
    "Further Tuning: Additional hyperparameter tuning and feature engineering could improve the performance of models like Random Forest and Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will use GridSearchCV to perform hyperparameter tuning for each of these models.\n",
    "\n",
    "Hyperparameter Tuning for Top 3 Models\n",
    "1. Support Vector Regression (SVR)\n",
    "2. Ridge Regression\n",
    "3. Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge, BayesianRidge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter List for the Model which will be tuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "# Define hyperparameter grids for each model\n",
    "\n",
    "param_grid_svr = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "param_grid_ridge = {\n",
    "    'alpha': [0.1, 1, 10, 100],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sag']\n",
    "}\n",
    "\n",
    "param_grid_bayesian = {\n",
    "    'n_iter': [100, 200, 300, 400, 500],\n",
    "    'alpha_1': [1e-6, 1e-5, 1e-4],\n",
    "    'alpha_2': [1e-6, 1e-5, 1e-4],\n",
    "    'lambda_1': [1e-6, 1e-5, 1e-4],\n",
    "    'lambda_2': [1e-6, 1e-5, 1e-4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "svr = SVR()\n",
    "ridge = Ridge()\n",
    "bayesian = BayesianRidge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the Grid Search CV to find the best parameter for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search for each model\n",
    "grid_svr = GridSearchCV(svr, param_grid_svr, cv=5, scoring='r2', n_jobs=-1, verbose=2)\n",
    "grid_ridge = GridSearchCV(ridge, param_grid_ridge, cv=5, scoring='r2', n_jobs=-1, verbose=2)\n",
    "grid_bayesian = GridSearchCV(bayesian, param_grid_bayesian, cv=5, scoring='r2', n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nitro Gaming\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_bayes.py:54: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.3 and will be removed in 1.5\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=BayesianRidge(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha_1&#x27;: [1e-06, 1e-05, 0.0001],\n",
       "                         &#x27;alpha_2&#x27;: [1e-06, 1e-05, 0.0001],\n",
       "                         &#x27;lambda_1&#x27;: [1e-06, 1e-05, 0.0001],\n",
       "                         &#x27;lambda_2&#x27;: [1e-06, 1e-05, 0.0001],\n",
       "                         &#x27;n_iter&#x27;: [100, 200, 300, 400, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=BayesianRidge(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha_1&#x27;: [1e-06, 1e-05, 0.0001],\n",
       "                         &#x27;alpha_2&#x27;: [1e-06, 1e-05, 0.0001],\n",
       "                         &#x27;lambda_1&#x27;: [1e-06, 1e-05, 0.0001],\n",
       "                         &#x27;lambda_2&#x27;: [1e-06, 1e-05, 0.0001],\n",
       "                         &#x27;n_iter&#x27;: [100, 200, 300, 400, 500]},\n",
       "             scoring=&#x27;r2&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: BayesianRidge</label><div class=\"sk-toggleable__content fitted\"><pre>BayesianRidge()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesianRidge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.BayesianRidge.html\">?<span>Documentation for BayesianRidge</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>BayesianRidge()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=BayesianRidge(), n_jobs=-1,\n",
       "             param_grid={'alpha_1': [1e-06, 1e-05, 0.0001],\n",
       "                         'alpha_2': [1e-06, 1e-05, 0.0001],\n",
       "                         'lambda_1': [1e-06, 1e-05, 0.0001],\n",
       "                         'lambda_2': [1e-06, 1e-05, 0.0001],\n",
       "                         'n_iter': [100, 200, 300, 400, 500]},\n",
       "             scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit grid searches\n",
    "grid_svr.fit(X_train, y_train)\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "grid_bayesian.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVR: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Best cross-validation R² score for SVR: 0.8411548315844988\n",
      "Best parameters for Ridge: {'alpha': 10, 'solver': 'lsqr'}\n",
      "Best cross-validation R² score for Ridge: 0.3074171887310845\n",
      "Best parameters for Bayesian: {'alpha_1': 1e-06, 'alpha_2': 0.0001, 'lambda_1': 0.0001, 'lambda_2': 1e-06, 'n_iter': 100}\n",
      "Best cross-validation R² score for Bayesian: -1.7565350932015051\n"
     ]
    }
   ],
   "source": [
    "# Print best parameters and scores for each model\n",
    "print(\"Best parameters for SVR:\", grid_svr.best_params_)\n",
    "print(\"Best cross-validation R² score for SVR:\", grid_svr.best_score_)\n",
    "\n",
    "print(\"Best parameters for Ridge:\", grid_ridge.best_params_)\n",
    "print(\"Best cross-validation R² score for Ridge:\", grid_ridge.best_score_)\n",
    "\n",
    "print(\"Best parameters for Bayesian:\", grid_bayesian.best_params_)\n",
    "print(\"Best cross-validation R² score for Bayesian:\", grid_bayesian.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now using the best parameters to tune the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               MAE       MSE        R2\n",
      "SVR       0.269002  0.199971  0.778042\n",
      "Ridge     0.466373  0.358771  0.601783\n",
      "Bayesian  0.435209  0.333465  0.629872\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best models on the test set\n",
    "best_svr = grid_svr.best_estimator_\n",
    "best_ridge = grid_ridge.best_estimator_\n",
    "best_bayesian = grid_bayesian.best_estimator_\n",
    "\n",
    "models = [(\"SVR\", best_svr), (\"Ridge\", best_ridge), (\"Bayesian\", best_bayesian)]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models:\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the results\n",
    "    results[name] = {\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"R2\": r2\n",
    "    }\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(model, f\"{name}_best_model.pkl\")\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('hypertuned_model_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with Polynomial Features - MAE: 0.28470374674347354, MSE: 0.2071481868718464, R2: 0.7700766161838215\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generate polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluate with SVR\n",
    "svr_poly = SVR(C=10, gamma='scale', kernel='rbf')  # Using best params from previous tuning\n",
    "svr_poly.fit(X_train_poly, y_train_poly)\n",
    "y_pred_poly = svr_poly.predict(X_test_poly)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_poly = mean_absolute_error(y_test_poly, y_pred_poly)\n",
    "mse_poly = mean_squared_error(y_test_poly, y_pred_poly)\n",
    "r2_poly = r2_score(y_test_poly, y_pred_poly)\n",
    "\n",
    "print(f\"SVR with Polynomial Features - MAE: {mae_poly}, MSE: {mse_poly}, R2: {r2_poly}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Ensembled Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model - MAE: 0.3805426571051523, MSE: 0.5474853138676409, R2: 0.39232064805864386\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define and train XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost Model - MAE: {mae_xgb}, MSE: {mse_xgb}, R2: {r2_xgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Models (Ensemble )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation MAE scores for each fold: [0.22542481 0.16927933 0.28900586 0.30879518 0.14519045]\n",
      "Cross-validation MSE scores for each fold: [0.10238496 0.06096286 0.13254362 0.12942435 0.02374588]\n",
      "Cross-validation R2 scores for each fold: [0.87587693 0.67114169 0.90873866 0.76880754 0.96013668]\n",
      "Mean cross-validated MAE: 0.22753912841317528\n",
      "Mean cross-validated MSE: 0.08981233463984364\n",
      "Mean cross-validated R2: 0.8369403000290113\n",
      "Test Set - Stacking Model - MAE: 0.21034456500762985, MSE: 0.09506965002700721, R2: 0.8944777844183961\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('ridge', Ridge(alpha=10)),\n",
    "    ('svr', SVR(C=10, gamma='scale', kernel='rbf')),\n",
    "    ('bayesian', BayesianRidge())\n",
    "]\n",
    "\n",
    "# Define stacking model\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "# Define KFold cross-validator\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate model using cross-validation\n",
    "cv_mae_scores = cross_val_score(stacking_model, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error')\n",
    "cv_mse_scores = cross_val_score(stacking_model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "cv_r2_scores = cross_val_score(stacking_model, X_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "# Print cross-validation results for each fold\n",
    "print(\"Cross-validation MAE scores for each fold:\", -cv_mae_scores)\n",
    "print(\"Cross-validation MSE scores for each fold:\", -cv_mse_scores)\n",
    "print(\"Cross-validation R2 scores for each fold:\", cv_r2_scores)\n",
    "\n",
    "# Print mean cross-validation scores\n",
    "print(f\"Mean cross-validated MAE: {-cv_mae_scores.mean()}\")\n",
    "print(f\"Mean cross-validated MSE: {-cv_mse_scores.mean()}\")\n",
    "print(f\"Mean cross-validated R2: {cv_r2_scores.mean()}\")\n",
    "\n",
    "# Train stacking model on full training set\n",
    "stacking_model.fit(X_train, y_train)\n",
    "y_pred_stack = stacking_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics on test set\n",
    "mae_stack = mean_absolute_error(y_test, y_pred_stack)\n",
    "mse_stack = mean_squared_error(y_test, y_pred_stack)\n",
    "r2_stack = r2_score(y_test, y_pred_stack)\n",
    "\n",
    "print(f\"Test Set - Stacking Model - MAE: {mae_stack}, MSE: {mse_stack}, R2: {r2_stack}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Experiment with Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import joblib\n",
    "\n",
    "# Load the final feature engineered data\n",
    "df_final = pd.read_csv('final_feature_engineered_data.csv')\n",
    "\n",
    "# Separate the features and target\n",
    "X = df_final.drop(columns=['Log_Arsenic'])\n",
    "y = df_final['Log_Arsenic']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a list of base models\n",
    "base_models = [\n",
    "    ('ridge', Ridge(alpha=10)),\n",
    "    ('svr', SVR(C=10, gamma='scale', kernel='rbf')),\n",
    "    ('bayesian', BayesianRidge()),\n",
    "    ('rf', RandomForestRegressor(random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(random_state=42)),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "]\n",
    "\n",
    "# Define a list of meta-models\n",
    "meta_models = [\n",
    "    ('linear', LinearRegression()),\n",
    "    ('ridge', Ridge(alpha=10)),\n",
    "    ('lasso', Lasso(alpha=0.1)),\n",
    "    ('elasticnet', ElasticNet(alpha=0.1))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    CV_Mean_R2  CV_Std_R2  \\\n",
      "Stacking_linear_with_ridge                            0.081148   0.392351   \n",
      "Stacking_linear_with_svr                              0.820242   0.140375   \n",
      "Stacking_linear_with_bayesian                         0.013654   0.257066   \n",
      "Stacking_linear_with_rf                               0.741289   0.136416   \n",
      "Stacking_linear_with_gb                               0.740399   0.222841   \n",
      "...                                                        ...        ...   \n",
      "Stacking_elasticnet_with_ridge_svr_bayesian_gb_knn    0.818225   0.097971   \n",
      "Stacking_elasticnet_with_ridge_svr_rf_gb_knn          0.838978   0.088808   \n",
      "Stacking_elasticnet_with_ridge_bayesian_rf_gb_knn     0.771861   0.140312   \n",
      "Stacking_elasticnet_with_svr_bayesian_rf_gb_knn       0.818597   0.097804   \n",
      "Stacking_elasticnet_with_ridge_svr_bayesian_rf_...    0.818279   0.097955   \n",
      "\n",
      "                                                         MAE       MSE  \\\n",
      "Stacking_linear_with_ridge                          0.491528  0.381131   \n",
      "Stacking_linear_with_svr                            0.202634  0.105406   \n",
      "Stacking_linear_with_bayesian                       0.618847  0.556424   \n",
      "Stacking_linear_with_rf                             0.381499  0.481085   \n",
      "Stacking_linear_with_gb                             0.397857  0.615138   \n",
      "...                                                      ...       ...   \n",
      "Stacking_elasticnet_with_ridge_svr_bayesian_gb_knn  0.316764  0.303450   \n",
      "Stacking_elasticnet_with_ridge_svr_rf_gb_knn        0.319557  0.317061   \n",
      "Stacking_elasticnet_with_ridge_bayesian_rf_gb_knn   0.420550  0.555156   \n",
      "Stacking_elasticnet_with_svr_bayesian_rf_gb_knn     0.319550  0.317048   \n",
      "Stacking_elasticnet_with_ridge_svr_bayesian_rf_...  0.319552  0.317055   \n",
      "\n",
      "                                                          R2  \n",
      "Stacking_linear_with_ridge                          0.576965  \n",
      "Stacking_linear_with_svr                            0.883005  \n",
      "Stacking_linear_with_bayesian                       0.382399  \n",
      "Stacking_linear_with_rf                             0.466021  \n",
      "Stacking_linear_with_gb                             0.317230  \n",
      "...                                                      ...  \n",
      "Stacking_elasticnet_with_ridge_svr_bayesian_gb_knn  0.663186  \n",
      "Stacking_elasticnet_with_ridge_svr_rf_gb_knn        0.648079  \n",
      "Stacking_elasticnet_with_ridge_bayesian_rf_gb_knn   0.383807  \n",
      "Stacking_elasticnet_with_svr_bayesian_rf_gb_knn     0.648094  \n",
      "Stacking_elasticnet_with_ridge_svr_bayesian_rf_...  0.648086  \n",
      "\n",
      "[252 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Define a list of base models\n",
    "base_models = [\n",
    "    ('ridge', Ridge(alpha=10)),\n",
    "    ('svr', SVR(C=10, gamma='scale', kernel='rbf')),\n",
    "    ('bayesian', BayesianRidge()),\n",
    "    ('rf', RandomForestRegressor(random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(random_state=42)),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "]\n",
    "\n",
    "# Define a list of meta-models\n",
    "meta_models = [\n",
    "    ('linear', LinearRegression()),\n",
    "    ('ridge', Ridge(alpha=10)),\n",
    "    ('lasso', Lasso(alpha=0.1)),\n",
    "    ('elasticnet', ElasticNet(alpha=0.1))\n",
    "]\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate through each combination of base models and meta-models\n",
    "for meta_name, meta_model in meta_models:\n",
    "    for i in range(1, len(base_models) + 1):\n",
    "        for base_combination in itertools.combinations(base_models, i):\n",
    "            # Ensure base_combination is a list\n",
    "            base_combination_list = list(base_combination)\n",
    "            \n",
    "            # Define the stacking model\n",
    "            stacking_model = StackingRegressor(\n",
    "                estimators=base_combination_list,\n",
    "                final_estimator=meta_model,\n",
    "                cv=kf,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            # Perform k-fold cross-validation\n",
    "            cv_results = cross_val_score(stacking_model, X_train, y_train, cv=kf, scoring='r2', n_jobs=-1)\n",
    "            mean_cv_r2 = cv_results.mean()\n",
    "            std_cv_r2 = cv_results.std()\n",
    "            \n",
    "            # Train the stacking model\n",
    "            stacking_model.fit(X_train, y_train)\n",
    "            y_pred_stack = stacking_model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mae_stack = mean_absolute_error(y_test, y_pred_stack)\n",
    "            mse_stack = mean_squared_error(y_test, y_pred_stack)\n",
    "            r2_stack = r2_score(y_test, y_pred_stack)\n",
    "            \n",
    "            # Store the results\n",
    "            model_name = f\"Stacking_{meta_name}_with_{'_'.join([name for name, _ in base_combination])}\"\n",
    "            results[model_name] = {\n",
    "                \"CV_Mean_R2\": mean_cv_r2,\n",
    "                \"CV_Std_R2\": std_cv_r2,\n",
    "                \"MAE\": mae_stack,\n",
    "                \"MSE\": mse_stack,\n",
    "                \"R2\": r2_stack\n",
    "            }\n",
    "\n",
    "            # Save the model\n",
    "            joblib.dump(stacking_model, f\"{model_name}.pkl\")\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('ensemble_model_comparison_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_Mean_R2</th>\n",
       "      <th>CV_Std_R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stacking_linear_with_ridge</th>\n",
       "      <td>0.081148</td>\n",
       "      <td>0.392351</td>\n",
       "      <td>0.491528</td>\n",
       "      <td>0.381131</td>\n",
       "      <td>0.576965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_linear_with_svr</th>\n",
       "      <td>0.820242</td>\n",
       "      <td>0.140375</td>\n",
       "      <td>0.202634</td>\n",
       "      <td>0.105406</td>\n",
       "      <td>0.883005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_linear_with_bayesian</th>\n",
       "      <td>0.013654</td>\n",
       "      <td>0.257066</td>\n",
       "      <td>0.618847</td>\n",
       "      <td>0.556424</td>\n",
       "      <td>0.382399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_linear_with_rf</th>\n",
       "      <td>0.741289</td>\n",
       "      <td>0.136416</td>\n",
       "      <td>0.381499</td>\n",
       "      <td>0.481085</td>\n",
       "      <td>0.466021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_linear_with_gb</th>\n",
       "      <td>0.740399</td>\n",
       "      <td>0.222841</td>\n",
       "      <td>0.397857</td>\n",
       "      <td>0.615138</td>\n",
       "      <td>0.317230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_elasticnet_with_ridge_svr_bayesian_gb_knn</th>\n",
       "      <td>0.818225</td>\n",
       "      <td>0.097971</td>\n",
       "      <td>0.316764</td>\n",
       "      <td>0.303450</td>\n",
       "      <td>0.663186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_elasticnet_with_ridge_svr_rf_gb_knn</th>\n",
       "      <td>0.838978</td>\n",
       "      <td>0.088808</td>\n",
       "      <td>0.319557</td>\n",
       "      <td>0.317061</td>\n",
       "      <td>0.648079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_elasticnet_with_ridge_bayesian_rf_gb_knn</th>\n",
       "      <td>0.771861</td>\n",
       "      <td>0.140312</td>\n",
       "      <td>0.420550</td>\n",
       "      <td>0.555156</td>\n",
       "      <td>0.383807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_elasticnet_with_svr_bayesian_rf_gb_knn</th>\n",
       "      <td>0.818597</td>\n",
       "      <td>0.097804</td>\n",
       "      <td>0.319550</td>\n",
       "      <td>0.317048</td>\n",
       "      <td>0.648094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking_elasticnet_with_ridge_svr_bayesian_rf_gb_knn</th>\n",
       "      <td>0.818279</td>\n",
       "      <td>0.097955</td>\n",
       "      <td>0.319552</td>\n",
       "      <td>0.317055</td>\n",
       "      <td>0.648086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    CV_Mean_R2  CV_Std_R2  \\\n",
       "Stacking_linear_with_ridge                            0.081148   0.392351   \n",
       "Stacking_linear_with_svr                              0.820242   0.140375   \n",
       "Stacking_linear_with_bayesian                         0.013654   0.257066   \n",
       "Stacking_linear_with_rf                               0.741289   0.136416   \n",
       "Stacking_linear_with_gb                               0.740399   0.222841   \n",
       "...                                                        ...        ...   \n",
       "Stacking_elasticnet_with_ridge_svr_bayesian_gb_knn    0.818225   0.097971   \n",
       "Stacking_elasticnet_with_ridge_svr_rf_gb_knn          0.838978   0.088808   \n",
       "Stacking_elasticnet_with_ridge_bayesian_rf_gb_knn     0.771861   0.140312   \n",
       "Stacking_elasticnet_with_svr_bayesian_rf_gb_knn       0.818597   0.097804   \n",
       "Stacking_elasticnet_with_ridge_svr_bayesian_rf_...    0.818279   0.097955   \n",
       "\n",
       "                                                         MAE       MSE  \\\n",
       "Stacking_linear_with_ridge                          0.491528  0.381131   \n",
       "Stacking_linear_with_svr                            0.202634  0.105406   \n",
       "Stacking_linear_with_bayesian                       0.618847  0.556424   \n",
       "Stacking_linear_with_rf                             0.381499  0.481085   \n",
       "Stacking_linear_with_gb                             0.397857  0.615138   \n",
       "...                                                      ...       ...   \n",
       "Stacking_elasticnet_with_ridge_svr_bayesian_gb_knn  0.316764  0.303450   \n",
       "Stacking_elasticnet_with_ridge_svr_rf_gb_knn        0.319557  0.317061   \n",
       "Stacking_elasticnet_with_ridge_bayesian_rf_gb_knn   0.420550  0.555156   \n",
       "Stacking_elasticnet_with_svr_bayesian_rf_gb_knn     0.319550  0.317048   \n",
       "Stacking_elasticnet_with_ridge_svr_bayesian_rf_...  0.319552  0.317055   \n",
       "\n",
       "                                                          R2  \n",
       "Stacking_linear_with_ridge                          0.576965  \n",
       "Stacking_linear_with_svr                            0.883005  \n",
       "Stacking_linear_with_bayesian                       0.382399  \n",
       "Stacking_linear_with_rf                             0.466021  \n",
       "Stacking_linear_with_gb                             0.317230  \n",
       "...                                                      ...  \n",
       "Stacking_elasticnet_with_ridge_svr_bayesian_gb_knn  0.663186  \n",
       "Stacking_elasticnet_with_ridge_svr_rf_gb_knn        0.648079  \n",
       "Stacking_elasticnet_with_ridge_bayesian_rf_gb_knn   0.383807  \n",
       "Stacking_elasticnet_with_svr_bayesian_rf_gb_knn     0.648094  \n",
       "Stacking_elasticnet_with_ridge_svr_bayesian_rf_...  0.648086  \n",
       "\n",
       "[252 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the best ensemble model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model based on test R² score:\n",
      "Unnamed: 0    Stacking_linear_with_svr_rf\n",
      "CV_Mean_R2                       0.794076\n",
      "CV_Std_R2                        0.183497\n",
      "MAE                              0.182704\n",
      "MSE                              0.073791\n",
      "R2                               0.918096\n",
      "Name: 12, dtype: object\n",
      "\n",
      "Best Model based on Cross-Validation Mean R² score:\n",
      "Unnamed: 0    Stacking_linear_with_svr_knn\n",
      "CV_Mean_R2                        0.879771\n",
      "CV_Std_R2                          0.10028\n",
      "MAE                               0.265883\n",
      "MSE                               0.124153\n",
      "R2                                0.862197\n",
      "Name: 14, dtype: object\n",
      "\n",
      "Top 5 Models based on test R² score:\n",
      "                                       Unnamed: 0  CV_Mean_R2  CV_Std_R2  \\\n",
      "12                    Stacking_linear_with_svr_rf    0.794076   0.183497   \n",
      "41     Stacking_linear_with_ridge_svr_bayesian_rf    0.639876   0.283577   \n",
      "56  Stacking_linear_with_ridge_svr_bayesian_rf_gb    0.404885   0.680023   \n",
      "31           Stacking_linear_with_svr_bayesian_rf    0.728839   0.282440   \n",
      "34                 Stacking_linear_with_svr_rf_gb    0.745078   0.201218   \n",
      "\n",
      "         MAE       MSE        R2  \n",
      "12  0.182704  0.073791  0.918096  \n",
      "41  0.198073  0.078027  0.913394  \n",
      "56  0.192374  0.087071  0.903356  \n",
      "31  0.213909  0.089995  0.900110  \n",
      "34  0.181319  0.091967  0.897922  \n",
      "\n",
      "Top 5 Models based on Cross-Validation Mean R² score:\n",
      "                                 Unnamed: 0  CV_Mean_R2  CV_Std_R2       MAE  \\\n",
      "14             Stacking_linear_with_svr_knn    0.879771   0.100280  0.265883   \n",
      "202         Stacking_elasticnet_with_svr_gb    0.845409   0.089937  0.316762   \n",
      "225     Stacking_elasticnet_with_svr_gb_knn    0.845409   0.089937  0.316762   \n",
      "243  Stacking_elasticnet_with_svr_rf_gb_knn    0.845243   0.089816  0.319550   \n",
      "223      Stacking_elasticnet_with_svr_rf_gb    0.845243   0.089816  0.319550   \n",
      "\n",
      "          MSE        R2  \n",
      "14   0.124153  0.862197  \n",
      "202  0.303447  0.663190  \n",
      "225  0.303447  0.663190  \n",
      "243  0.317048  0.648094  \n",
      "223  0.317048  0.648094  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the results DataFrame\n",
    "results_df = pd.read_csv('ensemble_model_comparison_results.csv')\n",
    "\n",
    "# Select the best model based on test R² score\n",
    "best_models_r2 = results_df.sort_values(by='R2', ascending=False)\n",
    "best_model_r2 = best_models_r2.iloc[0]\n",
    "print(\"Best Model based on test R² score:\")\n",
    "print(best_model_r2)\n",
    "\n",
    "# Select the best model based on Cross-Validation Mean R² score\n",
    "best_models_cv_r2 = results_df.sort_values(by='CV_Mean_R2', ascending=False)\n",
    "best_model_cv_r2 = best_models_cv_r2.iloc[0]\n",
    "print(\"\\nBest Model based on Cross-Validation Mean R² score:\")\n",
    "print(best_model_cv_r2)\n",
    "\n",
    "# Optionally, display the top 5 models based on each criterion\n",
    "top_5_models_r2 = best_models_r2.head(5)\n",
    "print(\"\\nTop 5 Models based on test R² score:\")\n",
    "print(top_5_models_r2)\n",
    "\n",
    "top_5_models_cv_r2 = best_models_cv_r2.head(5)\n",
    "print(\"\\nTop 5 Models based on Cross-Validation Mean R² score:\")\n",
    "print(top_5_models_cv_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CV_Mean_R2</th>\n",
       "      <th>CV_Std_R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stacking_linear_with_svr_knn</td>\n",
       "      <td>0.879771</td>\n",
       "      <td>0.100280</td>\n",
       "      <td>0.265883</td>\n",
       "      <td>0.124153</td>\n",
       "      <td>0.862197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Stacking_elasticnet_with_svr_gb</td>\n",
       "      <td>0.845409</td>\n",
       "      <td>0.089937</td>\n",
       "      <td>0.316762</td>\n",
       "      <td>0.303447</td>\n",
       "      <td>0.663190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Stacking_elasticnet_with_svr_gb_knn</td>\n",
       "      <td>0.845409</td>\n",
       "      <td>0.089937</td>\n",
       "      <td>0.316762</td>\n",
       "      <td>0.303447</td>\n",
       "      <td>0.663190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Stacking_elasticnet_with_svr_rf_gb_knn</td>\n",
       "      <td>0.845243</td>\n",
       "      <td>0.089816</td>\n",
       "      <td>0.319550</td>\n",
       "      <td>0.317048</td>\n",
       "      <td>0.648094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Stacking_elasticnet_with_svr_rf_gb</td>\n",
       "      <td>0.845243</td>\n",
       "      <td>0.089816</td>\n",
       "      <td>0.319550</td>\n",
       "      <td>0.317048</td>\n",
       "      <td>0.648094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Unnamed: 0  CV_Mean_R2  CV_Std_R2       MAE  \\\n",
       "14             Stacking_linear_with_svr_knn    0.879771   0.100280  0.265883   \n",
       "202         Stacking_elasticnet_with_svr_gb    0.845409   0.089937  0.316762   \n",
       "225     Stacking_elasticnet_with_svr_gb_knn    0.845409   0.089937  0.316762   \n",
       "243  Stacking_elasticnet_with_svr_rf_gb_knn    0.845243   0.089816  0.319550   \n",
       "223      Stacking_elasticnet_with_svr_rf_gb    0.845243   0.089816  0.319550   \n",
       "\n",
       "          MSE        R2  \n",
       "14   0.124153  0.862197  \n",
       "202  0.303447  0.663190  \n",
       "225  0.303447  0.663190  \n",
       "243  0.317048  0.648094  \n",
       "223  0.317048  0.648094  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_models_cv_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CV_Mean_R2</th>\n",
       "      <th>CV_Std_R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stacking_linear_with_svr_rf</td>\n",
       "      <td>0.794076</td>\n",
       "      <td>0.183497</td>\n",
       "      <td>0.182704</td>\n",
       "      <td>0.073791</td>\n",
       "      <td>0.918096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Stacking_linear_with_ridge_svr_bayesian_rf</td>\n",
       "      <td>0.639876</td>\n",
       "      <td>0.283577</td>\n",
       "      <td>0.198073</td>\n",
       "      <td>0.078027</td>\n",
       "      <td>0.913394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Stacking_linear_with_ridge_svr_bayesian_rf_gb</td>\n",
       "      <td>0.404885</td>\n",
       "      <td>0.680023</td>\n",
       "      <td>0.192374</td>\n",
       "      <td>0.087071</td>\n",
       "      <td>0.903356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Stacking_linear_with_svr_bayesian_rf</td>\n",
       "      <td>0.728839</td>\n",
       "      <td>0.282440</td>\n",
       "      <td>0.213909</td>\n",
       "      <td>0.089995</td>\n",
       "      <td>0.900110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Stacking_linear_with_svr_rf_gb</td>\n",
       "      <td>0.745078</td>\n",
       "      <td>0.201218</td>\n",
       "      <td>0.181319</td>\n",
       "      <td>0.091967</td>\n",
       "      <td>0.897922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Unnamed: 0  CV_Mean_R2  CV_Std_R2  \\\n",
       "12                    Stacking_linear_with_svr_rf    0.794076   0.183497   \n",
       "41     Stacking_linear_with_ridge_svr_bayesian_rf    0.639876   0.283577   \n",
       "56  Stacking_linear_with_ridge_svr_bayesian_rf_gb    0.404885   0.680023   \n",
       "31           Stacking_linear_with_svr_bayesian_rf    0.728839   0.282440   \n",
       "34                 Stacking_linear_with_svr_rf_gb    0.745078   0.201218   \n",
       "\n",
       "         MAE       MSE        R2  \n",
       "12  0.182704  0.073791  0.918096  \n",
       "41  0.198073  0.078027  0.913394  \n",
       "56  0.192374  0.087071  0.903356  \n",
       "31  0.213909  0.089995  0.900110  \n",
       "34  0.181319  0.091967  0.897922  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_models_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the best model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of the New Stacking Model:\n",
    "Cross-validation MAE: 0.2275\n",
    "Cross-validation MSE: 0.0898\n",
    "Cross-validation R2: 0.8369\n",
    "Test MAE: 0.2103\n",
    "Test MSE: 0.0951\n",
    "Test R2: 0.8945\n",
    "\n",
    "\n",
    "## Previous Best Models from the Tables:\n",
    "\n",
    "### Top Models Based on Cross-Validation Mean R² Score:\n",
    "\n",
    "Stacking_linear_with_svr_knn\n",
    "CV_Mean_R2: 0.8798\n",
    "CV_Std_R2: 0.1003\n",
    "MAE: 0.2659\n",
    "MSE: 0.1242\n",
    "R2: 0.8622\n",
    "\n",
    "### Top Models Based on Test R² Score:\n",
    "\n",
    "Stacking_linear_with_svr_rf\n",
    "CV_Mean_R2: 0.7941\n",
    "CV_Std_R2: 0.1835\n",
    "MAE: 0.1827\n",
    "MSE: 0.0738\n",
    "R2: 0.9181\n",
    "\n",
    "## Comparison:\n",
    "### Cross-Validation Metrics:\n",
    "\n",
    "New Stacking Model: CV_R2: 0.8369, CV_MAE: 0.2275, CV_MSE: 0.0898\n",
    "Stacking_linear_with_svr_knn: CV_R2: 0.8798, CV_MAE: 0.2659, CV_MSE: 0.1242\n",
    "Stacking_linear_with_svr_rf: CV_R2: 0.7941, CV_MAE: 0.1827, CV_MSE: 0.0738\n",
    "\n",
    "\n",
    "### Test Set Metrics:\n",
    "\n",
    "New Stacking Model: R2: 0.8945, MAE: 0.2103, MSE: 0.0951\n",
    "Stacking_linear_with_svr_knn: R2: 0.8622, MAE: 0.2659, MSE: 0.1242\n",
    "Stacking_linear_with_svr_rf: R2: 0.9181, MAE: 0.1827, MSE: 0.0738\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "## Best Model Based on Test Set R² Score:\n",
    "\n",
    "### Stacking_linear_with_svr_rf: Test R²: 0.9181, Test MAE: 0.1827, Test MSE: 0.0738\n",
    "\n",
    "### Best Model Based on Cross-Validation Mean R² Score:\n",
    "\n",
    "### Stacking_linear_with_svr_knn: CV_R2: 0.8798, CV_MAE: 0.2659, CV_MSE: 0.1242\n",
    "\n",
    "New Stacking Model:\n",
    "\n",
    "\n",
    "Test R²: 0.8945 (second highest)\n",
    "CV_R2: 0.8369 (second highest among provided models)\n",
    "\n",
    "The new stacking model performs very well in terms of test set performance and has solid cross-validation results.\n",
    "\n",
    "### Given the performance metrics, Stacking_linear_with_svr_rf remains the best model overall due to its highest R² score on the test set. \n",
    "\n",
    "However, the new stacking model with base models ridge, svr, and bayesian, and a LinearRegression final estimator also performs exceptionally well and could be a very strong alternative.\n",
    "\n",
    "## Final Decision:\n",
    "Primary Choice: Stacking_linear_with_svr_rf\n",
    "\n",
    "Strong Alternative: The new stacking model (ridge, svr, bayesian with LinearRegression as final estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Results:\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, CV_Mean_R2, CV_Std_R2, MAE, MSE, R2]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Stacking_new_model_ridge_svr_bayesian.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'Stacking_linear_with_svr_rf' is the best model based on the analysis\n",
    "best_model_name = 'Stacking_linear_with_svr_rf'\n",
    "\n",
    "# Load the best model\n",
    "best_model = joblib.load(f\"{best_model_name}.pkl\")\n",
    "\n",
    "# Save the best model with a new name for clarity\n",
    "joblib.dump(best_model, 'best_stacking_model.pkl')\n",
    "\n",
    "# Document the final results\n",
    "best_model_results = results_df.loc[results_df.index == best_model_name]\n",
    "print(\"Best Model Results:\")\n",
    "print(best_model_results)\n",
    "\n",
    "# Save the best model results to a CSV file\n",
    "best_model_results.to_csv('best_model_results.csv', index=False)\n",
    "\n",
    "# Optionally, save the strong alternative model\n",
    "alternative_model_name = 'Stacking_new_model_ridge_svr_bayesian'\n",
    "joblib.dump(stacking_model, f\"{alternative_model_name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
